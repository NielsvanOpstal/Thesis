{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29739892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ec31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from get_data import get_data\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.tensorflow import balanced_batch_generator\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed = 31)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce305bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3bf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, ID = get_data(\"../Data/filled/grids/\", [2015,2016,2017,2018,2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d24f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658c7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w15c.pickle', 'rb') as handle:\n",
    "    wt = pickle.load(handle)\n",
    "    \n",
    "with open('w16c.pickle', 'rb') as handle:\n",
    "    wv = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0544fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_samples(grid, block, dims = 39):\n",
    "    \n",
    "    nonzero = np.transpose(grid[:,:,-2].nonzero()) # Get indices of nonzero componetns\n",
    "\n",
    "    size = nonzero.shape[0]\n",
    "    width = block * 2 + 1 # calculate widht and height. Needed later on\n",
    "    \n",
    "    X = np.zeros((size, width, width, dims))\n",
    "    Y = np.zeros(size)\n",
    "    ID = np.zeros(size)\n",
    "    \n",
    "    for idx, i in enumerate(nonzero):\n",
    "        x, ID[idx], Y[idx] = get_neighbor_grid(grid, i, block)\n",
    "        X[idx] = x.reshape(width,width, 39)\n",
    "        \n",
    "    X = np.moveaxis(X, -1, 1) # order the indices correctly to make sure it works in CNN\n",
    "    X = torch.from_numpy(X).float()\n",
    "    Y = torch.from_numpy(Y).float()\n",
    "    \n",
    "    return X,ID,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bf83dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_neighbor_grid(full, hw, block = 1):\n",
    "    \n",
    "    # get the nonzero (built) blocks by checking if they have a ID\n",
    "\n",
    "    h = hw[0]\n",
    "    w = hw[1]\n",
    "    \n",
    "    y = full[h,w,-1]\n",
    "    ID = full[h,w,-2]\n",
    "    \n",
    "    hu = h - block\n",
    "    hd = h + block\n",
    "    hshort, hextra, wshort, wextra = 0,0,0,0\n",
    "    if hu < 0:\n",
    "        hshort = 0 - hu\n",
    "        hu = 0\n",
    "    if hd >= full.shape[0]:\n",
    "        hextra = (hd - full.shape[0]) + 1\n",
    "        hd = full.shape[0]\n",
    "\n",
    "    wr = w + block\n",
    "    wl = w - block\n",
    "\n",
    "    if wr >= full.shape[1]:\n",
    "        wextra = (wr - full.shape[1]) + 1\n",
    "        wr = full.shape[1]\n",
    "    if wl < 0:\n",
    "        wshort = 0 - wl\n",
    "        wl = 0\n",
    "\n",
    "    nb = full[hu : hd + 1, wl : wr + 1, :]\n",
    "    nb = np.pad(nb, ((hshort, hextra), (wshort, wextra), (0,0)), mode = \"constant\", constant_values = 0)\n",
    "    return nb[:,:,:-2], ID, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f890120d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "ID_train = []\n",
    "for filename in os.listdir(\"../Data/filled/grids/2015/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2015/\" + filename)\n",
    "    X, ID, Y = create_CNN_samples(n, 5)\n",
    "    X_train.append(X)\n",
    "    Y_train.append(Y)\n",
    "    ID_train.append(ID)\n",
    "    \n",
    "Y_train = np.concatenate(Y_train)\n",
    "ID_train = np.concatenate(ID_train)\n",
    "X_train = np.concatenate(X_train)\n",
    "\n",
    "X_train = np.moveaxis(X_train, 1, -1)\n",
    "X_train = X_train.reshape(-1, 39)\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_train = X_train.reshape(-1, 11, 11, 39)\n",
    "\n",
    "X_train = np.moveaxis(X_train, -1, 1)\n",
    "X_train = torch.tensor(X_train).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "ID_val = []\n",
    "\n",
    "for filename in os.listdir(\"../Data/filled/grids/2016/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2016/\" + filename)\n",
    "    X, ID, Y = create_CNN_samples(n, 5)\n",
    "    X_val.append(X)\n",
    "    Y_val.append(Y)\n",
    "    ID_val.append(ID)\n",
    "    \n",
    "X_val = np.concatenate(X_val)\n",
    "X_val = np.moveaxis(X_val, 1, -1)\n",
    "X_val = X_val.reshape(-1, 39)\n",
    "\n",
    "X_val = ss.transform(X_val)\n",
    "\n",
    "\n",
    "X_val = X_val.reshape(-1, 11, 11, 39)\n",
    "X_val = np.moveaxis(X_val, -1, 1)\n",
    "Y_val = np.concatenate(Y_val)\n",
    "ID_val = np.concatenate(ID_val)\n",
    "X_val = torch.tensor(X_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ab3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y):\n",
    "    \n",
    "    y1 = np.argwhere(Y==1)\n",
    "    percentage1 = len(y1) / len(X)\n",
    "    while percentage1 < 0.4:\n",
    "        X = np.append(X, X[y1].squeeze(), axis = 0)\n",
    "        Y = np.append(Y, Y[y1].squeeze(), axis = 0) \n",
    "        percentage1 = (Y==1).sum() / len(X)\n",
    "    \n",
    "\n",
    "#     return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c333d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model3, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b5471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model4, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216b1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = Model1(\"een\", w)\n",
    "# model2 = Model2(\"twee\")\n",
    "# model3 = Model3(\"drie\")\n",
    "# model4 = Model4(\"vier\")\n",
    "# models = [model1, model2, model3, model4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a5e968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2893058., 2870455., 2868833., ..., 1311910., 1176428., 1314791.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f836c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225c26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 32, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1))\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        \n",
    "        self.name = name\n",
    "\n",
    "       \n",
    "    def forward(self, x, w, y, train = True):\n",
    "\n",
    "        out = self.net(x)\n",
    "        neighbors = [w.neighbors[x] for x in range(len(out))]\n",
    "        transitions = [out[x] for x in neighbors]\n",
    "        n_function = torch.zeros((len(out), w.max_neighbors + 1))\n",
    "        for i, (t, idx) in enumerate(zip(transitions, range(len(out)))):\n",
    "            n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "            n_function[i, 0] = out[idx]      \n",
    "        if train:\n",
    "#             indices = np.arange(len(n_function)).reshape(-1,1)\n",
    "#             under, y  = RandomUnderSampler().fit_resample(indices, y)\n",
    "#             n_function = n_function[under].squeeze()\n",
    "#             print(n_function)\n",
    "\n",
    "            return n_function.mean(axis = 1), y.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return self.final(n_function.sum(axis =1 )), y\n",
    "            \n",
    "    \n",
    "    def get_no_activation(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac4a6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1(\"een\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "588476f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_part(model, X, idxs, w):\n",
    "    preds = model(X)\n",
    "    preds = pd.DataFrame(np.array(preds.detach())).set_index(idxs)\n",
    "    \n",
    "    neighbors = [w.neighbors[x] for x in idxs]\n",
    "    transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "    n_function = np.zeros((len(preds), w.max_neighbors + 1))\n",
    "    for i, (t, idx) in enumerate(zip(transitions, idxs)):\n",
    "        n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "        n_function[i, 0] = preds.loc[idx]\n",
    "        \n",
    "    return n_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6219a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# # optimizer = optim.RMSprop(model.parameters(), lr=0.001) \n",
    "# BCEloss = nn.BCELoss()\n",
    "# model.train()\n",
    "\n",
    "def train_model(model, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, wv, num_epochs, batch_per_e = 1):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.01) \n",
    "    BCEloss = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(len(Y_train) / (Y_train == 1).sum()))\n",
    "    train_loss = []\n",
    "    train_loss_history = []\n",
    "    acc_history = []\n",
    "    ROC_history = []\n",
    "    f1_score_history = []\n",
    "    cmc_best = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        print(\"epoch: {} of {}\".format(epoch, num_epochs))\n",
    "        \n",
    "            \n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time.time()\n",
    "\n",
    "        out, y_ = model(X_train, wt, Y_train)\n",
    "\n",
    "        \n",
    "        loss = BCEloss(out, torch.tensor(y_).float().squeeze())\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_history.append(loss)\n",
    "                \n",
    "        model.eval()\n",
    "        \n",
    "        out, y = model(X_val, wv, Y_val, False)\n",
    "\n",
    "        out = out.detach().numpy()\n",
    "        print(out)\n",
    "        out =  (out > 0.5).astype(int)\n",
    "        print(out)\n",
    "        acc = accuracy_score(y, out)\n",
    "        ROC = roc_auc_score(y, out)\n",
    "        f1 = f1_score(y, out)\n",
    "\n",
    "        acc_history.append(acc)\n",
    "        ROC_history.append(ROC)\n",
    "        train_loss_history.append(train_loss)\n",
    "        f1_score_history.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"training_loss: {:.4f}, acc: {:.3f}, ROC: {:.3f}, f1: {:.3f}\".format(loss, acc, ROC , f1))\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "    return acc_history, ROC_history, train_loss_history, f1_score_history\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876e7ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 of 100\n",
      "tensor(1.3268, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 1.3268, acc: 0.079, ROC: 0.500, f1: 0.147\n",
      "epoch: 1 of 100\n",
      "tensor(801.3655, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 801.3655, acc: 0.921, ROC: 0.500, f1: 0.000\n",
      "epoch: 2 of 100\n",
      "tensor(76.1194, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[1.6652913e-05 5.6664292e-13 4.1139433e-13 ... 4.3424500e-12 2.9497910e-06\n",
      " 1.4462873e-06]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 76.1194, acc: 0.920, ROC: 0.500, f1: 0.001\n",
      "epoch: 3 of 100\n",
      "tensor(8.7281, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.8367634 1.        1.        ... 0.9999298 0.9101262 0.9746878]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 8.7281, acc: 0.079, ROC: 0.500, f1: 0.147\n",
      "epoch: 4 of 100\n",
      "tensor(5.6930, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[2.0806346e-09 1.7059128e-21 1.2888110e-21 ... 1.2567504e-18 4.7541404e-10\n",
      " 4.3963999e-10]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 5.6930, acc: 0.888, ROC: 0.509, f1: 0.077\n",
      "epoch: 5 of 100\n",
      "tensor(5.5746, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.8614617  0.9999372  0.99991643 ... 0.99362916 0.891819   0.94728273]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 5.5746, acc: 0.084, ROC: 0.500, f1: 0.147\n",
      "epoch: 6 of 100\n",
      "tensor(2.6041, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[1.2889282e-02 9.5185032e-06 8.6540167e-06 ... 6.2452409e-06 4.3698195e-03\n",
      " 2.5380165e-03]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 2.6041, acc: 0.834, ROC: 0.524, f1: 0.130\n",
      "epoch: 7 of 100\n",
      "tensor(1.9405, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.610715   0.9528431  0.94506633 ... 0.56280845 0.54258484 0.6165695 ]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 1.9405, acc: 0.114, ROC: 0.504, f1: 0.148\n",
      "epoch: 8 of 100\n",
      "tensor(1.5879, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.07816038 0.00100818 0.00093756 ... 0.00045103 0.03442604 0.02631097]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.5879, acc: 0.769, ROC: 0.542, f1: 0.158\n",
      "epoch: 9 of 100\n",
      "tensor(1.5111, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.5539308  0.7796623  0.7596693  ... 0.3433886  0.4583467  0.50760204]\n",
      "[1 1 1 ... 0 0 1]\n",
      "training_loss: 1.5111, acc: 0.150, ROC: 0.516, f1: 0.151\n",
      "epoch: 10 of 100\n",
      "tensor(1.4189, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.14665425 0.00537183 0.00506061 ... 0.00258154 0.07529351 0.06120657]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.4189, acc: 0.732, ROC: 0.552, f1: 0.167\n",
      "epoch: 11 of 100\n",
      "tensor(1.3943, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.5256158  0.60592055 0.58811307 ... 0.27503312 0.42244923 0.4616342 ]\n",
      "[1 1 1 ... 0 0 0]\n",
      "training_loss: 1.3943, acc: 0.215, ROC: 0.529, f1: 0.154\n",
      "epoch: 12 of 100\n",
      "tensor(1.3562, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.20495604 0.01442018 0.01371542 ... 0.00770663 0.11860459 0.10170126]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3562, acc: 0.695, ROC: 0.561, f1: 0.173\n",
      "epoch: 13 of 100\n",
      "tensor(1.3400, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.49679893 0.46078897 0.44581464 ... 0.22811659 0.39866728 0.42452788]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3400, acc: 0.274, ROC: 0.545, f1: 0.159\n",
      "epoch: 14 of 100\n",
      "tensor(1.3208, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.245368   0.02534731 0.02427441 ... 0.01495456 0.15319915 0.13651162]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3208, acc: 0.667, ROC: 0.566, f1: 0.175\n",
      "epoch: 15 of 100\n",
      "tensor(1.3097, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.48073927 0.367434   0.3555255  ... 0.20155556 0.3819652  0.4021161 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3097, acc: 0.254, ROC: 0.546, f1: 0.160\n",
      "epoch: 16 of 100\n",
      "tensor(1.3747, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.15739217 0.00644338 0.0062222  ... 0.00557371 0.09628211 0.07255829]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3747, acc: 0.768, ROC: 0.552, f1: 0.168\n",
      "epoch: 17 of 100\n",
      "tensor(1.3780, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.5311113  0.6594479  0.6486354  ... 0.45535117 0.49657956 0.54393643]\n",
      "[1 1 1 ... 0 0 1]\n",
      "training_loss: 1.3780, acc: 0.130, ROC: 0.509, f1: 0.149\n",
      "epoch: 18 of 100\n",
      "tensor(1.3448, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.21128492 0.01607944 0.0157275  ... 0.01193818 0.13604341 0.10916901]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3448, acc: 0.716, ROC: 0.563, f1: 0.176\n",
      "epoch: 19 of 100\n",
      "tensor(1.3308, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.49394125 0.5090623  0.5003074  ... 0.32568148 0.44247103 0.47092554]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.3308, acc: 0.221, ROC: 0.536, f1: 0.157\n",
      "epoch: 20 of 100\n",
      "tensor(1.3126, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.25055835 0.02953206 0.02899382 ... 0.02092612 0.16967924 0.14258909]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3126, acc: 0.676, ROC: 0.571, f1: 0.179\n",
      "epoch: 21 of 100\n",
      "tensor(1.3047, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.46495926 0.40270874 0.39556864 ... 0.25495142 0.40522197 0.42503527]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.3047, acc: 0.297, ROC: 0.549, f1: 0.161\n",
      "epoch: 22 of 100\n",
      "tensor(1.2959, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.27680534 0.0440164  0.04316753 ... 0.03107239 0.19519114 0.17073292]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2959, acc: 0.645, ROC: 0.573, f1: 0.179\n",
      "epoch: 23 of 100\n",
      "tensor(1.2917, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.44238868 0.33078578 0.32484657 ... 0.2134929  0.37892684 0.39431468]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2917, acc: 0.350, ROC: 0.558, f1: 0.164\n",
      "epoch: 24 of 100\n",
      "tensor(1.2872, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.29447162 0.057618   0.05641196 ... 0.04095552 0.2138325  0.19222932]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2872, acc: 0.620, ROC: 0.574, f1: 0.178\n",
      "epoch: 25 of 100\n",
      "tensor(1.2842, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.42758414 0.28991634 0.28442916 ... 0.1910653  0.36248282 0.37577125]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2842, acc: 0.382, ROC: 0.565, f1: 0.168\n",
      "epoch: 26 of 100\n",
      "tensor(1.2806, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.30458984 0.06747427 0.06588504 ... 0.04863724 0.22522762 0.20586225]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2806, acc: 0.606, ROC: 0.574, f1: 0.178\n",
      "epoch: 27 of 100\n",
      "tensor(1.2795, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4164276  0.26295686 0.25725678 ... 0.17775807 0.3507739  0.36326632]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2795, acc: 0.405, ROC: 0.569, f1: 0.170\n",
      "epoch: 28 of 100\n",
      "tensor(1.2770, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.31075883 0.0750804  0.07301293 ... 0.05495989 0.23290554 0.21618836]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2770, acc: 0.596, ROC: 0.575, f1: 0.178\n",
      "epoch: 29 of 100\n",
      "tensor(1.2753, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.40900862 0.24874297 0.2423486  ... 0.17134319 0.34337834 0.3562046 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2753, acc: 0.418, ROC: 0.572, f1: 0.171\n",
      "epoch: 30 of 100\n",
      "tensor(1.2759, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.31356278 0.0798673  0.07740913 ... 0.05898827 0.23685256 0.2224185 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2759, acc: 0.591, ROC: 0.576, f1: 0.178\n",
      "epoch: 31 of 100\n",
      "tensor(1.2747, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.40550205 0.24390616 0.23692462 ... 0.17003264 0.34016827 0.35369462]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2747, acc: 0.424, ROC: 0.572, f1: 0.171\n",
      "epoch: 32 of 100\n",
      "tensor(1.2735, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.3135068  0.08129707 0.07851711 ... 0.06078919 0.23759295 0.22485797]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2735, acc: 0.590, ROC: 0.577, f1: 0.178\n",
      "epoch: 33 of 100\n",
      "tensor(1.2726, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4035041  0.24340922 0.23577042 ... 0.17119722 0.33885616 0.35362074]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2726, acc: 0.425, ROC: 0.572, f1: 0.171\n",
      "epoch: 34 of 100\n",
      "tensor(1.2723, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.3135948  0.08304796 0.08001419 ... 0.06260141 0.23859622 0.22773653]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2723, acc: 0.590, ROC: 0.577, f1: 0.179\n",
      "epoch: 35 of 100\n",
      "tensor(1.2706, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4005933  0.23915504 0.23124425 ... 0.17061076 0.33648482 0.35198304]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2706, acc: 0.430, ROC: 0.574, f1: 0.172\n",
      "epoch: 36 of 100\n",
      "tensor(1.2706, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31408438 0.08500921 0.08178816 ... 0.0648412  0.23993276 0.23121771]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2706, acc: 0.589, ROC: 0.577, f1: 0.179\n",
      "epoch: 37 of 100\n",
      "tensor(1.2702, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.40090904 0.24353571 0.23549342 ... 0.17504366 0.33753952 0.35421374]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2702, acc: 0.428, ROC: 0.574, f1: 0.172\n",
      "epoch: 38 of 100\n",
      "tensor(1.2702, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.31163305 0.0836584  0.08050764 ... 0.0643174  0.23778409 0.2307973 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2702, acc: 0.593, ROC: 0.578, f1: 0.179\n",
      "epoch: 39 of 100\n",
      "tensor(1.2694, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.40153304 0.24805033 0.23992659 ... 0.17975028 0.33918953 0.35706565]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2694, acc: 0.425, ROC: 0.574, f1: 0.172\n",
      "epoch: 40 of 100\n",
      "tensor(1.2697, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.30855936 0.08125778 0.07821184 ... 0.06287358 0.23514363 0.22946432]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2697, acc: 0.598, ROC: 0.578, f1: 0.180\n",
      "epoch: 41 of 100\n",
      "tensor(1.2691, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.40635803 0.26345453 0.2551497  ... 0.1916128  0.34572524 0.36546102]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2691, acc: 0.414, ROC: 0.572, f1: 0.171\n",
      "epoch: 42 of 100\n",
      "tensor(1.2691, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.30234742 0.07554705 0.0727403  ... 0.05896269 0.22906724 0.22395565]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2691, acc: 0.609, ROC: 0.580, f1: 0.181\n",
      "epoch: 43 of 100\n",
      "tensor(1.2691, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.41124752 0.27838418 0.2698956  ... 0.20321661 0.3519616  0.37354174]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2691, acc: 0.403, ROC: 0.569, f1: 0.169\n",
      "epoch: 44 of 100\n",
      "tensor(1.2697, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.29732662 0.07093658 0.06834743 ... 0.05596876 0.22421768 0.21878922]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2697, acc: 0.618, ROC: 0.580, f1: 0.182\n",
      "epoch: 45 of 100\n",
      "tensor(1.2694, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.41767642 0.2993805  0.29080313 ... 0.21917841 0.36043316 0.38423213]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2694, acc: 0.387, ROC: 0.567, f1: 0.168\n",
      "epoch: 46 of 100\n",
      "tensor(1.2703, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.28992373 0.06440637 0.0620645  ... 0.05113402 0.21682422 0.20978011]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2703, acc: 0.630, ROC: 0.580, f1: 0.182\n",
      "epoch: 47 of 100\n",
      "tensor(1.2699, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.42587265 0.32576457 0.3170727  ... 0.23705858 0.37039015 0.39622495]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2699, acc: 0.369, ROC: 0.564, f1: 0.167\n",
      "epoch: 48 of 100\n",
      "tensor(1.2707, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.28215533 0.05806901 0.05598087 ... 0.04622419 0.20884201 0.20000984]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2707, acc: 0.643, ROC: 0.580, f1: 0.183\n",
      "epoch: 49 of 100\n",
      "tensor(1.2723, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.43865782 0.36799234 0.35909238 ... 0.26810673 0.38605934 0.41535822]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2723, acc: 0.337, ROC: 0.560, f1: 0.165\n",
      "epoch: 50 of 100\n",
      "tensor(1.2733, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.27090335 0.04939835 0.04765392 ... 0.03953697 0.19737825 0.18623818]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2733, acc: 0.662, ROC: 0.581, f1: 0.185\n",
      "epoch: 51 of 100\n",
      "tensor(1.2759, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45378903 0.41897887 0.4093281  ... 0.30424014 0.40428585 0.43694517]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2759, acc: 0.302, ROC: 0.555, f1: 0.163\n",
      "epoch: 52 of 100\n",
      "tensor(1.2775, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.2598559  0.04161092 0.0401738  ... 0.0334809  0.18596122 0.17241894]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2775, acc: 0.680, ROC: 0.581, f1: 0.187\n",
      "epoch: 53 of 100\n",
      "tensor(1.2805, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.46844712 0.47190818 0.4615563  ... 0.34223425 0.42182925 0.45756227]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2805, acc: 0.266, ROC: 0.548, f1: 0.160\n",
      "epoch: 54 of 100\n",
      "tensor(1.2829, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.249227   0.03494099 0.03375925 ... 0.02806054 0.17469402 0.15859519]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2829, acc: 0.695, ROC: 0.578, f1: 0.186\n",
      "epoch: 55 of 100\n",
      "tensor(1.2854, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.48371536 0.527951   0.51747423 ... 0.38293996 0.44016117 0.47767743]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2854, acc: 0.230, ROC: 0.541, f1: 0.158\n",
      "epoch: 56 of 100\n",
      "tensor(1.2873, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.23940185 0.02978883 0.02879332 ... 0.02372435 0.16463137 0.14719988]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2873, acc: 0.710, ROC: 0.578, f1: 0.187\n",
      "epoch: 57 of 100\n",
      "tensor(1.2921, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4971257  0.5771696  0.567096   ... 0.4194414  0.4565452  0.49483225]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2921, acc: 0.199, ROC: 0.532, f1: 0.155\n",
      "epoch: 58 of 100\n",
      "tensor(1.2930, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.23280054 0.02661827 0.02575668 ... 0.02109206 0.15787603 0.13978   ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2930, acc: 0.722, ROC: 0.579, f1: 0.189\n",
      "epoch: 59 of 100\n",
      "tensor(1.2967, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.50765455 0.6159167  0.60636187 ... 0.4464538  0.46875563 0.50558704]\n",
      "[1 1 1 ... 0 0 1]\n",
      "training_loss: 1.2967, acc: 0.181, ROC: 0.527, f1: 0.154\n",
      "epoch: 60 of 100\n",
      "tensor(1.2962, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.23224254 0.02631759 0.02550151 ... 0.02023833 0.15617128 0.13730164]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2962, acc: 0.727, ROC: 0.579, f1: 0.190\n",
      "epoch: 61 of 100\n",
      "tensor(1.2986, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.50928396 0.6310804  0.62182236 ... 0.45175964 0.4706191  0.5046462 ]\n",
      "[1 1 1 ... 0 0 1]\n",
      "training_loss: 1.2986, acc: 0.181, ROC: 0.526, f1: 0.154\n",
      "epoch: 62 of 100\n",
      "tensor(1.2962, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.23587191 0.02824191 0.02738562 ... 0.0209029  0.1586903  0.13926277]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2962, acc: 0.726, ROC: 0.579, f1: 0.190\n",
      "epoch: 63 of 100\n",
      "tensor(1.2966, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.506263   0.62884444 0.61988944 ... 0.44210714 0.46656412 0.49586222]\n",
      "[1 1 1 ... 0 0 0]\n",
      "training_loss: 1.2966, acc: 0.194, ROC: 0.530, f1: 0.155\n",
      "epoch: 64 of 100\n",
      "tensor(1.2919, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.24532741 0.03380382 0.03276542 ... 0.02398686 0.1670105  0.14744663]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2919, acc: 0.719, ROC: 0.579, f1: 0.189\n",
      "epoch: 65 of 100\n",
      "tensor(1.2924, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.49780667 0.61113423 0.60239553 ... 0.421861   0.45641562 0.48159763]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2924, acc: 0.216, ROC: 0.537, f1: 0.157\n",
      "epoch: 66 of 100\n",
      "tensor(1.2874, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.25358176 0.03946697 0.03830648 ... 0.02727117 0.17459877 0.15518525]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2874, acc: 0.712, ROC: 0.579, f1: 0.188\n",
      "epoch: 67 of 100\n",
      "tensor(1.2861, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.48797747 0.5876851  0.5791236  ... 0.39748836 0.4446135  0.46741974]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2861, acc: 0.245, ROC: 0.544, f1: 0.159\n",
      "epoch: 68 of 100\n",
      "tensor(1.2816, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.26213267 0.0465722  0.04524662 ... 0.03139926 0.18302739 0.16408215]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2816, acc: 0.704, ROC: 0.580, f1: 0.188\n",
      "epoch: 69 of 100\n",
      "tensor(1.2807, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.47954962 0.56926477 0.5609497  ... 0.3799089  0.435099   0.45644638]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2807, acc: 0.268, ROC: 0.547, f1: 0.160\n",
      "epoch: 70 of 100\n",
      "tensor(1.2772, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.26969233 0.05367526 0.05218067 ... 0.03543126 0.19063443 0.17218314]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2772, acc: 0.696, ROC: 0.580, f1: 0.187\n",
      "epoch: 71 of 100\n",
      "tensor(1.2765, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.47179154 0.5506594  0.54260314 ... 0.3618725  0.42602372 0.44588238]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2765, acc: 0.291, ROC: 0.551, f1: 0.162\n",
      "epoch: 72 of 100\n",
      "tensor(1.2727, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.27567542 0.06004794 0.0584975  ... 0.03913403 0.19685526 0.17884107]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2727, acc: 0.692, ROC: 0.580, f1: 0.187\n",
      "epoch: 73 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2728, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4665425  0.53846514 0.5306407  ... 0.3508498  0.42033377 0.43913436]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2728, acc: 0.308, ROC: 0.555, f1: 0.163\n",
      "epoch: 74 of 100\n",
      "tensor(1.2701, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.27958834 0.06487305 0.06336583 ... 0.04170964 0.2010312  0.18321398]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2701, acc: 0.689, ROC: 0.581, f1: 0.187\n",
      "epoch: 75 of 100\n",
      "tensor(1.2693, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45894286 0.51837474 0.51080334 ... 0.3340471  0.41159895 0.42918703]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2693, acc: 0.330, ROC: 0.559, f1: 0.165\n",
      "epoch: 76 of 100\n",
      "tensor(1.2664, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.28552932 0.07219663 0.07065065 ... 0.04627083 0.20775239 0.1904513 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2664, acc: 0.682, ROC: 0.581, f1: 0.187\n",
      "epoch: 77 of 100\n",
      "tensor(1.2667, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45402044 0.50587624 0.49851182 ... 0.32470897 0.4063444  0.42328364]\n",
      "[0 1 0 ... 0 0 0]\n",
      "training_loss: 1.2667, acc: 0.344, ROC: 0.561, f1: 0.165\n",
      "epoch: 78 of 100\n",
      "tensor(1.2647, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.2890728  0.07677002 0.07522272 ... 0.04894941 0.21155654 0.19436659]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2647, acc: 0.680, ROC: 0.582, f1: 0.187\n",
      "epoch: 79 of 100\n",
      "tensor(1.2653, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.451825   0.50220394 0.49499494 ... 0.32247826 0.40469536 0.42129937]\n",
      "[0 1 0 ... 0 0 0]\n",
      "training_loss: 1.2653, acc: 0.352, ROC: 0.562, f1: 0.166\n",
      "epoch: 80 of 100\n",
      "tensor(1.2640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.29139763 0.08013722 0.07864084 ... 0.05112306 0.21428432 0.19730607]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2640, acc: 0.678, ROC: 0.582, f1: 0.187\n",
      "epoch: 81 of 100\n",
      "tensor(1.2625, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.44832283 0.49261114 0.4855625  ... 0.31516588 0.4009798  0.41673562]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2625, acc: 0.364, ROC: 0.563, f1: 0.167\n",
      "epoch: 82 of 100\n",
      "tensor(1.2620, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.29365176 0.08332453 0.08191694 ... 0.05323191 0.2169799  0.20026246]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2620, acc: 0.677, ROC: 0.582, f1: 0.188\n",
      "epoch: 83 of 100\n",
      "tensor(1.2627, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.44788373 0.49381918 0.48677    ... 0.31787512 0.401653   0.41734838]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2627, acc: 0.366, ROC: 0.564, f1: 0.167\n",
      "epoch: 84 of 100\n",
      "tensor(1.2614, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.29227528 0.08206499 0.08071019 ... 0.05261503 0.21606572 0.19888674]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2614, acc: 0.680, ROC: 0.581, f1: 0.187\n",
      "epoch: 85 of 100\n",
      "tensor(1.2608, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.447525   0.49503982 0.48793614 ... 0.32016447 0.40209636 0.41799775]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2608, acc: 0.367, ROC: 0.564, f1: 0.167\n",
      "epoch: 86 of 100\n",
      "tensor(1.2606, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.29016402 0.07936711 0.07804552 ... 0.05135433 0.21442947 0.19663191]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2606, acc: 0.683, ROC: 0.581, f1: 0.187\n",
      "epoch: 87 of 100\n",
      "tensor(1.2628, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45207384 0.51225823 0.5050424  ... 0.33300394 0.40831378 0.42466283]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2628, acc: 0.358, ROC: 0.562, f1: 0.166\n",
      "epoch: 88 of 100\n",
      "tensor(1.2616, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.28840896 0.07707312 0.07577699 ... 0.05016563 0.21279053 0.19443141]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2616, acc: 0.688, ROC: 0.580, f1: 0.187\n",
      "epoch: 89 of 100\n",
      "tensor(1.2631, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45425504 0.5218996  0.51464504 ... 0.34054998 0.41158274 0.42842978]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2631, acc: 0.354, ROC: 0.561, f1: 0.165\n",
      "epoch: 90 of 100\n",
      "tensor(1.2621, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.2875035  0.07616185 0.0748999  ... 0.04941437 0.21219179 0.19311252]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2621, acc: 0.691, ROC: 0.580, f1: 0.187\n",
      "epoch: 91 of 100\n",
      "tensor(1.2625, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45591322 0.5296933  0.522438   ... 0.34714854 0.4144195  0.43150085]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2625, acc: 0.350, ROC: 0.560, f1: 0.165\n",
      "epoch: 92 of 100\n",
      "tensor(1.2629, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.2861235  0.07435548 0.07312515 ... 0.04848957 0.21127816 0.19135173]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2629, acc: 0.695, ROC: 0.580, f1: 0.188\n",
      "epoch: 93 of 100\n",
      "tensor(1.2626, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.45789438 0.5387862  0.53148365 ... 0.3535784  0.41754827 0.4345844 ]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2626, acc: 0.347, ROC: 0.560, f1: 0.165\n",
      "epoch: 94 of 100\n",
      "tensor(1.2626, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.2842451  0.0719258  0.07070958 ... 0.0471829  0.20968656 0.18900692]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2626, acc: 0.699, ROC: 0.581, f1: 0.188\n",
      "epoch: 95 of 100\n",
      "tensor(1.2635, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.46023998 0.5485789  0.5411367  ... 0.36168918 0.42157918 0.43849573]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2635, acc: 0.341, ROC: 0.559, f1: 0.165\n",
      "epoch: 96 of 100\n",
      "tensor(1.2641, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.2811886  0.0680595  0.06688133 ... 0.0449682  0.20687836 0.18509819]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2641, acc: 0.704, ROC: 0.580, f1: 0.188\n",
      "epoch: 97 of 100\n",
      "tensor(1.2657, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.46525422 0.5673496  0.5597177  ... 0.37541053 0.42812315 0.44584626]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2657, acc: 0.330, ROC: 0.556, f1: 0.164\n",
      "epoch: 98 of 100\n",
      "tensor(1.2644, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.27963647 0.06578334 0.06464995 ... 0.04339537 0.20541243 0.18241829]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2644, acc: 0.709, ROC: 0.580, f1: 0.189\n",
      "epoch: 99 of 100\n",
      "tensor(1.2663, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4680301  0.5793742  0.57160705 ... 0.38367265 0.43193117 0.44990972]\n",
      "[0 1 1 ... 0 0 0]\n",
      "training_loss: 1.2663, acc: 0.324, ROC: 0.555, f1: 0.163\n"
     ]
    }
   ],
   "source": [
    "out1 = train_model(model, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, wv, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbe69db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 of 1000\n",
      "tensor(1.2410, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 1.2410, acc: 0.079, ROC: 0.500, f1: 0.147\n",
      "epoch: 1 of 1000\n",
      "tensor(113.6155, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.05392889 0.00064442 0.00063491 ... 0.00177575 0.04499425 0.04129361]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 113.6155, acc: 0.910, ROC: 0.515, f1: 0.074\n",
      "epoch: 2 of 1000\n",
      "tensor(1.5731, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.995981  1.        1.        ... 0.999997  0.9977756 0.9984238]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 1.5731, acc: 0.079, ROC: 0.500, f1: 0.147\n",
      "epoch: 3 of 1000\n",
      "tensor(3.5810, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4730444  0.39475468 0.39587796 ... 0.44473293 0.47315583 0.4730444 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 3.5810, acc: 0.557, ROC: 0.583, f1: 0.180\n",
      "epoch: 4 of 1000\n",
      "tensor(1.2719, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.47307694 0.38558444 0.3866775  ... 0.43232006 0.47307694 0.4693018 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2719, acc: 0.579, ROC: 0.588, f1: 0.184\n",
      "epoch: 5 of 1000\n",
      "tensor(1.2670, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4730357  0.3734899  0.3745745  ... 0.41806376 0.4730357  0.4621012 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2670, acc: 0.652, ROC: 0.591, f1: 0.191\n",
      "epoch: 6 of 1000\n",
      "tensor(1.2608, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.47322065 0.35921738 0.36467806 ... 0.40501392 0.47322065 0.4553552 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2608, acc: 0.527, ROC: 0.581, f1: 0.178\n",
      "epoch: 7 of 1000\n",
      "tensor(1.2586, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[6.3688986e-02 3.9802719e-05 4.3716398e-05 ... 7.3715276e-04 4.5751233e-02\n",
      " 3.2854557e-02]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2586, acc: 0.857, ROC: 0.553, f1: 0.176\n",
      "epoch: 8 of 1000\n",
      "tensor(1.6055, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4789439  0.43908665 0.43076885 ... 0.45921952 0.47934267 0.47913656]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.6055, acc: 0.315, ROC: 0.551, f1: 0.162\n",
      "epoch: 9 of 1000\n",
      "tensor(1.2711, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.47711113 0.42220038 0.41440785 ... 0.455572   0.47749645 0.4773242 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2711, acc: 0.368, ROC: 0.559, f1: 0.165\n",
      "epoch: 10 of 1000\n",
      "tensor(1.2646, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4757403  0.40971738 0.4074557  ... 0.4527859  0.47610682 0.47593832]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2646, acc: 0.407, ROC: 0.565, f1: 0.168\n",
      "epoch: 11 of 1000\n",
      "tensor(1.2619, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4746267  0.3998631  0.40157554 ... 0.45053014 0.4749787  0.4748106 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2619, acc: 0.439, ROC: 0.569, f1: 0.170\n",
      "epoch: 12 of 1000\n",
      "tensor(1.2601, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4736901  0.39410165 0.39656126 ... 0.4486353  0.4740308  0.47386175]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2601, acc: 0.463, ROC: 0.572, f1: 0.172\n",
      "epoch: 13 of 1000\n",
      "tensor(1.2590, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.47313005 0.38732064 0.38981354 ... 0.4472318  0.47320968 0.47313005]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2590, acc: 0.484, ROC: 0.574, f1: 0.173\n",
      "epoch: 14 of 1000\n",
      "tensor(1.2580, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.4726266  0.378641   0.38116124 ... 0.4460045  0.4726266  0.4726266 ]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2580, acc: 0.504, ROC: 0.577, f1: 0.175\n",
      "epoch: 15 of 1000\n",
      "tensor(1.2568, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1091265120 bytes. Buy new RAM!\n00007FFF7D8A783900007FFF7D8A77F0 c10.dll!c10::ThrowEnforceNotMet [<unknown file> @ <unknown line number>]\n00007FFF7D88A56700007FFF7D88A3F0 c10.dll!c10::alloc_cpu [<unknown file> @ <unknown line number>]\n00007FFF7D88A6E200007FFF7D88A6C0 c10.dll!c10::DefaultCPUAllocator::allocate [<unknown file> @ <unknown line number>]\n00007FFF7D886B5000007FFF7D886B20 c10.dll!c10::Allocator::raw_allocate [<unknown file> @ <unknown line number>]\n00007FFF1B7E734B00007FFF1B7E6720 torch_cpu.dll!at::native::mkldnn_convolution_backward_weights [<unknown file> @ <unknown line number>]\n00007FFF1B7DB30B00007FFF1B7D4A10 torch_cpu.dll!at::native::_fft_mkl [<unknown file> @ <unknown line number>]\n00007FFF1B7DC8CE00007FFF1B7DBC20 torch_cpu.dll!at::native::mkldnn_mul_out [<unknown file> @ <unknown line number>]\n00007FFF1B7DDE6000007FFF1B7DBC20 torch_cpu.dll!at::native::mkldnn_mul_out [<unknown file> @ <unknown line number>]\n00007FFF1B7E694800007FFF1B7E6720 torch_cpu.dll!at::native::mkldnn_convolution_backward_weights [<unknown file> @ <unknown line number>]\n00007FFF1B9A266700007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B98E02700007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B8FCADE00007FFF1B8FC970 torch_cpu.dll!at::mkldnn_convolution_backward_weights [<unknown file> @ <unknown line number>]\n00007FFF1B7E623D00007FFF1B7E6020 torch_cpu.dll!at::native::mkldnn_convolution_backward [<unknown file> @ <unknown line number>]\n00007FFF1B9A237B00007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B98E42400007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B8FC38D00007FFF1B8FC200 torch_cpu.dll!at::mkldnn_convolution_backward [<unknown file> @ <unknown line number>]\n00007FFF1CB09CDA00007FFF1CAB7970 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFF1B98E42400007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B8FC38D00007FFF1B8FC200 torch_cpu.dll!at::mkldnn_convolution_backward [<unknown file> @ <unknown line number>]\n00007FFF1CA2580600007FFF1CA25560 torch_cpu.dll!torch::autograd::generated::MkldnnConvolutionBackward::apply [<unknown file> @ <unknown line number>]\n00007FFF1C9FD96700007FFF1C9FD760 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFF1CED59F900007FFF1CED54A0 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFF1CED65A500007FFF1CED6290 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFF1CEDB52C00007FFF1CEDB220 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFF1CED7BFF00007FFF1CED7A10 torch_cpu.dll!torch::autograd::Engine::execute_with_graph_task [<unknown file> @ <unknown line number>]\n00007FFF5A12307800007FFF5A0FC550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFF1CED793D00007FFF1CED7600 torch_cpu.dll!torch::autograd::Engine::execute [<unknown file> @ <unknown line number>]\n00007FFF5A122F4400007FFF5A0FC550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFF5A12190000007FFF5A0FC550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFF3DCAD06500007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAD92F00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAEB5900007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DCAD9F700007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE41200007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DCAD9F700007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCADF6300007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DCAD9F700007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE00F00007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DC75B4C00007FFF3DC757E0 python37.dll!PyImport_Import [<unknown file> @ <unknown line number>]\n00007FFF3DC75A1100007FFF3DC757E0 python37.dll!PyImport_Import [<unknown file> @ <unknown line number>]\n00007FFF3DCACDC000007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAD92F00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE00F00007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC9389400007FFF3DC9364C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFF3DCF4CC400007FFF3DCCE8F0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFF3DC9389400007FFF3DC9364C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFF3DCF4CC400007FFF3DCCE8F0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFF3DC9389400007FFF3DC9364C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFF3DCACDE100007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAD76C00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCADF6300007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DCAD8CB00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE00F00007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DCAD8CB00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCADF6300007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DC9725A00007FFF3DC970A0 python37.dll!PyFunction_FastCallDict [<unknown file> @ <unknown line number>]\n00007FFF3DC9620A00007FFF3DC95E60 python37.dll!PyMethodDef_RawFastCallDict [<unknown file> @ <unknown line number>]\n00007FFF3DCBCE3400007FFF3DCBCC80 python37.dll!PySlice_New [<unknown file> @ <unknown line number>]\n00007FFF3DCAECD400007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GEBRUI~1\\AppData\\Local\\Temp/ipykernel_1232/189972023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mID_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mID_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\GEBRUI~1\\AppData\\Local\\Temp/ipykernel_1232/2224040489.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, wv, num_epochs, batch_per_e)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBCEloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mtrain_loss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1091265120 bytes. Buy new RAM!\n00007FFF7D8A783900007FFF7D8A77F0 c10.dll!c10::ThrowEnforceNotMet [<unknown file> @ <unknown line number>]\n00007FFF7D88A56700007FFF7D88A3F0 c10.dll!c10::alloc_cpu [<unknown file> @ <unknown line number>]\n00007FFF7D88A6E200007FFF7D88A6C0 c10.dll!c10::DefaultCPUAllocator::allocate [<unknown file> @ <unknown line number>]\n00007FFF7D886B5000007FFF7D886B20 c10.dll!c10::Allocator::raw_allocate [<unknown file> @ <unknown line number>]\n00007FFF1B7E734B00007FFF1B7E6720 torch_cpu.dll!at::native::mkldnn_convolution_backward_weights [<unknown file> @ <unknown line number>]\n00007FFF1B7DB30B00007FFF1B7D4A10 torch_cpu.dll!at::native::_fft_mkl [<unknown file> @ <unknown line number>]\n00007FFF1B7DC8CE00007FFF1B7DBC20 torch_cpu.dll!at::native::mkldnn_mul_out [<unknown file> @ <unknown line number>]\n00007FFF1B7DDE6000007FFF1B7DBC20 torch_cpu.dll!at::native::mkldnn_mul_out [<unknown file> @ <unknown line number>]\n00007FFF1B7E694800007FFF1B7E6720 torch_cpu.dll!at::native::mkldnn_convolution_backward_weights [<unknown file> @ <unknown line number>]\n00007FFF1B9A266700007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B98E02700007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B8FCADE00007FFF1B8FC970 torch_cpu.dll!at::mkldnn_convolution_backward_weights [<unknown file> @ <unknown line number>]\n00007FFF1B7E623D00007FFF1B7E6020 torch_cpu.dll!at::native::mkldnn_convolution_backward [<unknown file> @ <unknown line number>]\n00007FFF1B9A237B00007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B98E42400007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B8FC38D00007FFF1B8FC200 torch_cpu.dll!at::mkldnn_convolution_backward [<unknown file> @ <unknown line number>]\n00007FFF1CB09CDA00007FFF1CAB7970 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFF1B98E42400007FFF1B92B700 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FFF1B8FC38D00007FFF1B8FC200 torch_cpu.dll!at::mkldnn_convolution_backward [<unknown file> @ <unknown line number>]\n00007FFF1CA2580600007FFF1CA25560 torch_cpu.dll!torch::autograd::generated::MkldnnConvolutionBackward::apply [<unknown file> @ <unknown line number>]\n00007FFF1C9FD96700007FFF1C9FD760 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFF1CED59F900007FFF1CED54A0 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFF1CED65A500007FFF1CED6290 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFF1CEDB52C00007FFF1CEDB220 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFF1CED7BFF00007FFF1CED7A10 torch_cpu.dll!torch::autograd::Engine::execute_with_graph_task [<unknown file> @ <unknown line number>]\n00007FFF5A12307800007FFF5A0FC550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFF1CED793D00007FFF1CED7600 torch_cpu.dll!torch::autograd::Engine::execute [<unknown file> @ <unknown line number>]\n00007FFF5A122F4400007FFF5A0FC550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFF5A12190000007FFF5A0FC550 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFF3DCAD06500007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAD92F00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAEB5900007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DCAD9F700007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE41200007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DCAD9F700007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCADF6300007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DCAD9F700007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE00F00007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DC75B4C00007FFF3DC757E0 python37.dll!PyImport_Import [<unknown file> @ <unknown line number>]\n00007FFF3DC75A1100007FFF3DC757E0 python37.dll!PyImport_Import [<unknown file> @ <unknown line number>]\n00007FFF3DCACDC000007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAD92F00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE00F00007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC9389400007FFF3DC9364C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFF3DCF4CC400007FFF3DCCE8F0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFF3DC9389400007FFF3DC9364C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFF3DCF4CC400007FFF3DCCE8F0 python37.dll!PyErr_NoMemory [<unknown file> @ <unknown line number>]\n00007FFF3DC9389400007FFF3DC9364C python37.dll!PyObject_GetAttrId [<unknown file> @ <unknown line number>]\n00007FFF3DCACDE100007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAD76C00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCADF6300007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DCAD8CB00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCAE00F00007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DCAD8CB00007FFF3DCACD10 python37.dll!PyMethodDef_RawFastCallKeywords [<unknown file> @ <unknown line number>]\n00007FFF3DCADF6300007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n00007FFF3DC975D600007FFF3DC97430 python37.dll!PyEval_EvalCodeWithName [<unknown file> @ <unknown line number>]\n00007FFF3DC9725A00007FFF3DC970A0 python37.dll!PyFunction_FastCallDict [<unknown file> @ <unknown line number>]\n00007FFF3DC9620A00007FFF3DC95E60 python37.dll!PyMethodDef_RawFastCallDict [<unknown file> @ <unknown line number>]\n00007FFF3DCBCE3400007FFF3DCBCC80 python37.dll!PySlice_New [<unknown file> @ <unknown line number>]\n00007FFF3DCAECD400007FFF3DCADB60 python37.dll!PyEval_EvalFrameDefault [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "out1 = train_model(model, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, wv, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf711864",
   "metadata": {},
   "outputs": [],
   "source": [
    "l(out, torch.tensor(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65136da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9eef98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hists = train_model(models[0], X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, 1)\n",
    "for mod in models:\n",
    "    hists = train_model(mod, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, 1)\n",
    "    n_function = neighbor_part(mod, X_train, ID_train, wt)\n",
    "        \n",
    "    oversample = SMOTE()\n",
    "    x, y = oversample.fit_resample(n_function, Y_train)\n",
    "\n",
    "    clf_bagger = RandomForestClassifier(max_depth = 12, oob_score = True)\n",
    "    clf_bagger.fit(x,y)\n",
    "    \n",
    "    n_function = neighbor_part(mod, X_val, ID_val, wv)\n",
    "    preds = clf_bagger.predict(n_function)\n",
    "    totacc = accuracy_score(Y_val, preds)\n",
    "    totf1 = f1_score(Y_val, preds)\n",
    "    totROC = roc_auc_score(Y_val, preds)\n",
    "    \n",
    "    \n",
    "#     with open(\"../results/CNN/\" + mod.name + \".csv\", \"a+\") as f:\n",
    "#         f.write(\"loss;acc;ROC;f1_score\\n\")\n",
    "#         f.write(str(hists[2]) + \";\" + str(hists[0]) + \";\" + str(hists[1]) + \";\" + str(hists[3]) + \"\\n\")\n",
    "#         f.write(\"--;\" + str(totacc) + \";\" + str(totROC) + \";\" + str(totf1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
