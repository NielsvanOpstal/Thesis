{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29739892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ec31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from get_data import get_data\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.tensorflow import balanced_batch_generator\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed = 31)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce305bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3bf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, ID = get_data(\"../Data/filled/grids/\", [2015,2016,2017,2018,2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d24f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658c7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w15c.pickle', 'rb') as handle:\n",
    "    wt = pickle.load(handle)\n",
    "    \n",
    "with open('w16c.pickle', 'rb') as handle:\n",
    "    wv = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0544fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_samples(grid, block, dims = 39):\n",
    "    \n",
    "    nonzero = np.transpose(grid[:,:,-2].nonzero()) # Get indices of nonzero componetns\n",
    "\n",
    "    size = nonzero.shape[0]\n",
    "    width = block * 2 + 1 # calculate widht and height. Needed later on\n",
    "    \n",
    "    X = np.zeros((size, width, width, dims))\n",
    "    Y = np.zeros(size)\n",
    "    ID = np.zeros(size)\n",
    "    \n",
    "    for idx, i in enumerate(nonzero):\n",
    "        x, ID[idx], Y[idx] = get_neighbor_grid(grid, i, block)\n",
    "        X[idx] = x.reshape(width,width, 39)\n",
    "        \n",
    "    X = np.moveaxis(X, -1, 1) # order the indices correctly to make sure it works in CNN\n",
    "    X = torch.from_numpy(X).float()\n",
    "    Y = torch.from_numpy(Y).float()\n",
    "    \n",
    "    return X,ID,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bf83dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_neighbor_grid(full, hw, block = 1):\n",
    "    \n",
    "    # get the nonzero (built) blocks by checking if they have a ID\n",
    "\n",
    "    h = hw[0]\n",
    "    w = hw[1]\n",
    "    \n",
    "    y = full[h,w,-1]\n",
    "    ID = full[h,w,-2]\n",
    "    \n",
    "    hu = h - block\n",
    "    hd = h + block\n",
    "    hshort, hextra, wshort, wextra = 0,0,0,0\n",
    "    if hu < 0:\n",
    "        hshort = 0 - hu\n",
    "        hu = 0\n",
    "    if hd >= full.shape[0]:\n",
    "        hextra = (hd - full.shape[0]) + 1\n",
    "        hd = full.shape[0]\n",
    "\n",
    "    wr = w + block\n",
    "    wl = w - block\n",
    "\n",
    "    if wr >= full.shape[1]:\n",
    "        wextra = (wr - full.shape[1]) + 1\n",
    "        wr = full.shape[1]\n",
    "    if wl < 0:\n",
    "        wshort = 0 - wl\n",
    "        wl = 0\n",
    "\n",
    "    nb = full[hu : hd + 1, wl : wr + 1, :]\n",
    "    nb = np.pad(nb, ((hshort, hextra), (wshort, wextra), (0,0)), mode = \"constant\", constant_values = 0)\n",
    "    return nb[:,:,:-2], ID, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f890120d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "ID_train = []\n",
    "for filename in os.listdir(\"../Data/filled/grids/2015/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2015/\" + filename)\n",
    "    X, ID, Y = create_CNN_samples(n, 5)\n",
    "    X_train.append(X)\n",
    "    Y_train.append(Y)\n",
    "    ID_train.append(ID)\n",
    "    \n",
    "Y_train = np.concatenate(Y_train)\n",
    "ID_train = np.concatenate(ID_train)\n",
    "X_train = np.concatenate(X_train)\n",
    "\n",
    "X_train = np.moveaxis(X_train, 1, -1)\n",
    "X_train = X_train.reshape(-1, 39)\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_train = X_train.reshape(-1, 11, 11, 39)\n",
    "\n",
    "X_train = np.moveaxis(X_train, -1, 1)\n",
    "X_train = torch.tensor(X_train).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "ID_val = []\n",
    "\n",
    "for filename in os.listdir(\"../Data/filled/grids/2016/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2016/\" + filename)\n",
    "    X, ID, Y = create_CNN_samples(n, 5)\n",
    "    X_val.append(X)\n",
    "    Y_val.append(Y)\n",
    "    ID_val.append(ID)\n",
    "    \n",
    "X_val = np.concatenate(X_val)\n",
    "X_val = np.moveaxis(X_val, 1, -1)\n",
    "X_val = X_val.reshape(-1, 39)\n",
    "\n",
    "X_val = ss.transform(X_val)\n",
    "\n",
    "\n",
    "X_val = X_val.reshape(-1, 11, 11, 39)\n",
    "X_val = np.moveaxis(X_val, -1, 1)\n",
    "Y_val = np.concatenate(Y_val)\n",
    "ID_val = np.concatenate(ID_val)\n",
    "X_val = torch.tensor(X_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ab3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y):\n",
    "    \n",
    "    y1 = np.argwhere(Y==1)\n",
    "    percentage1 = len(y1) / len(X)\n",
    "    while percentage1 < 0.4:\n",
    "        X = np.append(X, X[y1].squeeze(), axis = 0)\n",
    "        Y = np.append(Y, Y[y1].squeeze(), axis = 0) \n",
    "        percentage1 = (Y==1).sum() / len(X)\n",
    "    \n",
    "\n",
    "#     return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c333d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model3, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b5471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model4, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216b1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = Model1(\"een\", w)\n",
    "# model2 = Model2(\"twee\")\n",
    "# model3 = Model3(\"drie\")\n",
    "# model4 = Model4(\"vier\")\n",
    "# models = [model1, model2, model3, model4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e95d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2893058., 2870455., 2868833., ..., 1311910., 1176428., 1314791.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f836c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225c26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 32, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1))\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        \n",
    "        self.name = name\n",
    "\n",
    "       \n",
    "    def forward(self, x, w, y, train = True):\n",
    "\n",
    "        out = self.net(x)\n",
    "        neighbors = [w.neighbors[x] for x in range(len(out))]\n",
    "        transitions = [out[x] for x in neighbors]\n",
    "        n_function = torch.zeros((len(out), w.max_neighbors + 1))\n",
    "        for i, (t, idx) in enumerate(zip(transitions, range(len(out)))):\n",
    "            n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "            n_function[i, 0] = out[idx]      \n",
    "        if train:\n",
    "#             indices = np.arange(len(n_function)).reshape(-1,1)\n",
    "#             under, y  = RandomUnderSampler().fit_resample(indices, y)\n",
    "#             n_function = n_function[under].squeeze()\n",
    "#             print(n_function)\n",
    "\n",
    "            return n_function.mean(axis = 1), y.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return self.final(n_function.sum(axis =1 )), y\n",
    "            \n",
    "    \n",
    "    def get_no_activation(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6077ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1(\"een\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "588476f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_part(model, X, idxs, w):\n",
    "    preds = model(X)\n",
    "    preds = pd.DataFrame(np.array(preds.detach())).set_index(idxs)\n",
    "    \n",
    "    neighbors = [w.neighbors[x] for x in idxs]\n",
    "    transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "    n_function = np.zeros((len(preds), w.max_neighbors + 1))\n",
    "    for i, (t, idx) in enumerate(zip(transitions, idxs)):\n",
    "        n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "        n_function[i, 0] = preds.loc[idx]\n",
    "        \n",
    "    return n_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6219a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# # optimizer = optim.RMSprop(model.parameters(), lr=0.001) \n",
    "# BCEloss = nn.BCELoss()\n",
    "# model.train()\n",
    "\n",
    "def train_model(model, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, wv, num_epochs, batch_per_e = 1):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.01) \n",
    "    BCEloss = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(len(Y_train) / (Y_train == 1).sum()))\n",
    "    train_loss = []\n",
    "    train_loss_history = []\n",
    "    acc_history = []\n",
    "    ROC_history = []\n",
    "    f1_score_history = []\n",
    "    cmc_best = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        print(\"epoch: {} of {}\".format(epoch, num_epochs))\n",
    "        \n",
    "            \n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time.time()\n",
    "\n",
    "        out, y_ = model(X_train, wt, Y_train)\n",
    "\n",
    "        \n",
    "        loss = BCEloss(out, torch.tensor(y_).float().squeeze())\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_history.append(loss)\n",
    "                \n",
    "        model.eval()\n",
    "        \n",
    "        out, y = model(X_val, wv, Y_val, False)\n",
    "\n",
    "        out = out.detach().numpy()\n",
    "        print(out)\n",
    "        out =  (out > 0.5).astype(int)\n",
    "        print(out)\n",
    "        acc = accuracy_score(y, out)\n",
    "        ROC = roc_auc_score(y, out)\n",
    "        f1 = f1_score(y, out)\n",
    "\n",
    "        acc_history.append(acc)\n",
    "        ROC_history.append(ROC)\n",
    "        train_loss_history.append(train_loss)\n",
    "        f1_score_history.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"training_loss: {:.4f}, acc: {:.3f}, ROC: {:.3f}, f1: {:.3f}\".format(loss, acc, ROC , f1))\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "    return acc_history, ROC_history, train_loss_history, f1_score_history\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93fd89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 of 100\n",
      "tensor(1.2605, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0 0 0 ... 0 0 0]\n",
      "training_loss: 1.2605, acc: 0.921, ROC: 0.500, f1: 0.000\n",
      "epoch: 1 of 100\n",
      "tensor(612.3113, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "[0.9999999 1.        1.        ... 1.        1.        1.       ]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training_loss: 612.3113, acc: 0.079, ROC: 0.500, f1: 0.147\n",
      "epoch: 2 of 100\n",
      "tensor(20.6967, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    }
   ],
   "source": [
    "out1 = train_model(model, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, wv, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5751514",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca96939",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e62b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "l(out, torch.tensor(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651650f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9eef98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hists = train_model(models[0], X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, 1)\n",
    "for mod in models:\n",
    "    hists = train_model(mod, X_train, Y_train, ID_train, wt, X_val, Y_val, ID_val, 1)\n",
    "    n_function = neighbor_part(mod, X_train, ID_train, wt)\n",
    "        \n",
    "    oversample = SMOTE()\n",
    "    x, y = oversample.fit_resample(n_function, Y_train)\n",
    "\n",
    "    clf_bagger = RandomForestClassifier(max_depth = 12, oob_score = True)\n",
    "    clf_bagger.fit(x,y)\n",
    "    \n",
    "    n_function = neighbor_part(mod, X_val, ID_val, wv)\n",
    "    preds = clf_bagger.predict(n_function)\n",
    "    totacc = accuracy_score(Y_val, preds)\n",
    "    totf1 = f1_score(Y_val, preds)\n",
    "    totROC = roc_auc_score(Y_val, preds)\n",
    "    \n",
    "    \n",
    "#     with open(\"../results/CNN/\" + mod.name + \".csv\", \"a+\") as f:\n",
    "#         f.write(\"loss;acc;ROC;f1_score\\n\")\n",
    "#         f.write(str(hists[2]) + \";\" + str(hists[0]) + \";\" + str(hists[1]) + \";\" + str(hists[3]) + \"\\n\")\n",
    "#         f.write(\"--;\" + str(totacc) + \";\" + str(totROC) + \";\" + str(totf1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
