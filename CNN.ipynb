{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29739892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ec31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from get_data import get_data\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.tensorflow import balanced_batch_generator\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed = 31)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce305bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3bf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, ID = get_data(\"../Data/filled/grids/\", [2015,2016,2017,2018,2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d24f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658c7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w15.pickle', 'rb') as handle:\n",
    "    wt = pickle.load(handle)\n",
    "    \n",
    "with open('w16.pickle', 'rb') as handle:\n",
    "    wv = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b392735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0544fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_samples(grid, block, dims = 39):\n",
    "    \n",
    "    nonzero = np.transpose(grid[:,:,-2].nonzero()) # Get indices of nonzero componetns\n",
    "\n",
    "    size = nonzero.shape[0]\n",
    "    width = block * 2 + 1 # calculate widht and height. Needed later on\n",
    "    \n",
    "    X = np.zeros((size, width, width, dims))\n",
    "    Y = np.zeros(size)\n",
    "    ID = np.zeros(size)\n",
    "    \n",
    "    for idx, i in enumerate(nonzero):\n",
    "        x, ID[idx], Y[idx] = get_neighbor_grid(grid, i, block)\n",
    "        X[idx] = x.reshape(width,width, 39)\n",
    "        \n",
    "    X = np.moveaxis(X, -1, 1) # order the indices correctly to make sure it works in CNN\n",
    "    X = torch.from_numpy(X).float()\n",
    "    Y = torch.from_numpy(Y).float()\n",
    "    \n",
    "    return X,ID,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bf83dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_neighbor_grid(full, hw, block = 1):\n",
    "    \n",
    "    # get the nonzero (built) blocks by checking if they have a ID\n",
    "\n",
    "    h = hw[0]\n",
    "    w = hw[1]\n",
    "    \n",
    "    y = full[h,w,-1]\n",
    "    ID = full[h,w,-2]\n",
    "    \n",
    "    hu = h - block\n",
    "    hd = h + block\n",
    "    hshort, hextra, wshort, wextra = 0,0,0,0\n",
    "    if hu < 0:\n",
    "        hshort = 0 - hu\n",
    "        hu = 0\n",
    "    if hd >= full.shape[0]:\n",
    "        hextra = (hd - full.shape[0]) + 1\n",
    "        hd = full.shape[0]\n",
    "\n",
    "    wr = w + block\n",
    "    wl = w - block\n",
    "\n",
    "    if wr >= full.shape[1]:\n",
    "        wextra = (wr - full.shape[1]) + 1\n",
    "        wr = full.shape[1]\n",
    "    if wl < 0:\n",
    "        wshort = 0 - wl\n",
    "        wl = 0\n",
    "\n",
    "    nb = full[hu : hd + 1, wl : wr + 1, :]\n",
    "    nb = np.pad(nb, ((hshort, hextra), (wshort, wextra), (0,0)), mode = \"constant\", constant_values = 0)\n",
    "    return nb[:,:,:-2], ID, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f890120d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "ID_train = []\n",
    "for filename in os.listdir(\"../Data/filled/grids/2015/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2015/\" + filename)\n",
    "    X, ID, Y = create_CNN_samples(n, 5)\n",
    "    X_train.append(X)\n",
    "    Y_train.append(Y)\n",
    "    ID_train.append(ID)\n",
    "    \n",
    "Y_train = np.concatenate(Y_train)\n",
    "ID_train = np.concatenate(ID_train)\n",
    "X_train = np.concatenate(X_train)\n",
    "\n",
    "X_train = np.moveaxis(X_train, 1, -1)\n",
    "X_train = X_train.reshape(-1, 39)\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_train = X_train.reshape(-1, 11, 11, 39)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "oversampler = SMOTE()\n",
    "X_train_resamp, Y_train_resamp = oversampler.fit_resample(X_train, Y_train)\n",
    "X_train = X_train.reshape(-1, 11, 11, 39)\n",
    "X_train_resamp = X_train_resamp.reshape(-1, 11, 11, 39)\n",
    "\n",
    "X_train = np.moveaxis(X_train, -1, 1)\n",
    "X_train_resamp = np.moveaxis(X_train_resamp, -1, 1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "ID_val = []\n",
    "\n",
    "for filename in os.listdir(\"../Data/filled/grids/2016/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2016/\" + filename)\n",
    "    X, ID, Y = create_CNN_samples(n, 5)\n",
    "    X_val.append(X)\n",
    "    Y_val.append(Y)\n",
    "    ID_val.append(ID)\n",
    "    \n",
    "X_val = np.concatenate(X_val)\n",
    "X_val = np.moveaxis(X_val, 1, -1)\n",
    "X_val = X_val.reshape(-1, 39)\n",
    "\n",
    "X_val = ss.transform(X_val)\n",
    "\n",
    "\n",
    "X_val = X_val.reshape(-1, 11, 11, 39)\n",
    "X_val = np.moveaxis(X_val, -1, 1)\n",
    "Y_val = np.concatenate(Y_val)\n",
    "ID_val = np.concatenate(ID_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2ab3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y, batch_size = 32):\n",
    "    \n",
    "    idxs = rng.integers(X.shape[0], size = batch_size)\n",
    "    \n",
    "    X = torch.from_numpy(X[idxs]).float()\n",
    "    Y = torch.from_numpy(Y[idxs]).float()\n",
    "    \n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "225c26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 32, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 8),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(8,1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "    \n",
    "    def get_no_activation(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf3bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c333d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model3, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Model4, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 64, kernel_size = (3,3)), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "        self.name = name\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216b1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model1(\"een\")\n",
    "model2 = Model2(\"twee\")\n",
    "model3 = Model3(\"drie\")\n",
    "model4 = Model4(\"vier\")\n",
    "models = [model1, model2, model3, model4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f836c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6219a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# # optimizer = optim.RMSprop(model.parameters(), lr=0.001) \n",
    "# BCEloss = nn.BCELoss()\n",
    "# model.train()\n",
    "\n",
    "def train_model(model, X_train, Y_train, X_val, Y_val, num_epochs, batch_per_e = 500):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.0001) \n",
    "    BCEloss = nn.BCELoss()\n",
    "    train_loss = []\n",
    "    train_loss_history = []\n",
    "    acc_history = []\n",
    "    ROC_history = []\n",
    "    f1_score_history = []\n",
    "    cmc_best = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        print(\"epoch: {} of {}\".format(epoch, num_epochs))\n",
    "        for batch in range(batch_per_e):\n",
    "            \n",
    "            x_train_, y_train_ = get_batch(X_train, Y_train)\n",
    "            model.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            t0 = time.time()\n",
    "            out = model(X_train)\n",
    "            print(t0-time.time())\n",
    "            loss = BCEloss(out.squeeze(), y_train_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 10 == 0:\n",
    "                train_loss.append(loss)\n",
    "                \n",
    "        model.eval()\n",
    "        \n",
    "        x_val_, y_val_ = get_batch(X_val, Y_val, batch_size = 1000)\n",
    "        predictions = model(x_val_).detach().numpy()\n",
    "        predictions = (predictions > 0.5).astype(int)\n",
    "        \n",
    "        acc = accuracy_score(y_val_, predictions)\n",
    "        ROC = roc_auc_score(y_val_, predictions)\n",
    "        f1 = f1_score(y_val_, predictions)\n",
    "        train_loss = (np.sum(train_loss) / (batch_per_e/10)).detach().item()\n",
    "\n",
    "        acc_history.append(acc)\n",
    "        ROC_history.append(ROC)\n",
    "        train_loss_history.append(train_loss)\n",
    "        f1_score_history.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"training_loss: {:.4f}, acc: {:.3f}, ROC: {:.3f}, f1: {:.3f}\".format(train_loss, acc, ROC , f1))\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "    return acc_history, ROC_history, train_loss_history, f1_score_history\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb9eef98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 of 250\n",
      "-2.5182645320892334\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GEBRUI~1\\AppData\\Local\\Temp/ipykernel_14992/3164399643.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mn_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbor_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mID_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moversample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\GEBRUI~1\\AppData\\Local\\Temp/ipykernel_14992/1824709830.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, Y_train, X_val, Y_val, num_epochs, batch_per_e)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBCEloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for mod in models:\n",
    "    hists = train_model(mod, X_train, Y_train, X_val, Y_val, 250)\n",
    "    n_function = neighbor_part(mod, X_train, ID_train, wt)\n",
    "        \n",
    "    oversample = SMOTE()\n",
    "    x, y = oversample.fit_resample(n_function, Y_train)\n",
    "\n",
    "    clf_bagger = RandomForestClassifier(max_depth = 12, oob_score = True)\n",
    "    clf_bagger.fit(x,y)\n",
    "    \n",
    "    n_function = neighbor_part(mod, X_val, ID_val, wv)\n",
    "    preds = clf_bagger.predict(n_function)\n",
    "    totacc = accuracy_score(Y_val, preds)\n",
    "    totf1 = f1_score(Y_val, preds)\n",
    "    totROC = roc_auc_score(Y_val, preds)\n",
    "    \n",
    "    \n",
    "    with open(\"../results/CNN/\" + mod.name + \".csv\", \"a+\") as f:\n",
    "        f.write(\"loss;acc;ROC;f1_score\\n\")\n",
    "        f.write(str(hists[2]) + \";\" + str(hists[0]) + \";\" + str(hists[1]) + \";\" + str(hists[3]) + \"\\n\")\n",
    "        f.write(\"--;\" + str(totacc) + \";\" + str(totROC) + \";\" + str(totf1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3cc8d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56367, 39, 11, 11)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "588476f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_part(model, X, idxs, w):\n",
    "    preds = model(X)\n",
    "    preds = pd.DataFrame(np.array(preds.detach())).set_index(idxs)\n",
    "    \n",
    "    neighbors = [w.neighbors[x] for x in idxs]\n",
    "    transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "    n_function = np.zeros((len(preds), w.max_neighbors + 1))\n",
    "    for i, (t, idx) in enumerate(zip(transitions, idxs)):\n",
    "        n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "        n_function[i, 0] = preds.loc[idx]\n",
    "        \n",
    "    return n_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3768ab",
   "metadata": {},
   "source": [
    "# Neighbor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fc9de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "import libpysal\n",
    "\n",
    "def load_data(year):\n",
    "    os.getcwd()\n",
    "    df = pd.DataFrame()\n",
    "    path = \"../Data/filled/\" + str(year) + \"/\"\n",
    "    for filename in os.listdir(path):\n",
    "        df1 = pd.read_csv(path + filename)\n",
    "        if df1.geometry.isna().any():\n",
    "            print(filename)\n",
    "        df = pd.concat([df, df1])\n",
    "    \n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df.geometry = df.geometry.apply(shapely.wkt.loads)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.drop([\"Unnamed: 0\", \"index\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7edf9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = load_data(2015)\n",
    "df16 = load_data(2016)\n",
    "wt = libpysal.weights.DistanceBand.from_dataframe(df15, threshold=150, binary = True, silence_warnings = True)\n",
    "wv = libpysal.weights.DistanceBand.from_dataframe(df16, threshold=150, binary = True, silence_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4589a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X15 = df15[df15.columns[:-4]]\n",
    "Y15 = df15.y\n",
    "\n",
    "X16 = df16[df16.columns[:-4]]\n",
    "Y16 = df16.y\n",
    "\n",
    "X15 = pd.DataFrame(scaler.fit_transform(X15))\n",
    "X16 = pd.DataFrame(scaler.transform(X16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f22a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = KMeans(n_clusters=5, random_state=0)\n",
    "labels15 = pd.DataFrame(cluster_model.fit_predict(X15))\n",
    "labels16 = pd.DataFrame(cluster_model.predict(X16))\n",
    "\n",
    "labels15[\"X\"] = X15.index\n",
    "labels16[\"X\"] = X16.index\n",
    "\n",
    "\n",
    "labels15 = labels15.set_index(0)\n",
    "labels16 = labels16.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8be9928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cbs_id_koppel.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5910fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# br.C28992R100 = br.C28992R100.map(b) # change C28992code for id\n",
    "labels15.C28 = labels15.C28.map(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b20b98b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>C28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2748208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2748211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2748212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2748245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2748263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56362</td>\n",
       "      <td>1413137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56363</td>\n",
       "      <td>1413181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56364</td>\n",
       "      <td>1414800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56365</td>\n",
       "      <td>1414808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56366</td>\n",
       "      <td>1416469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56367 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X      C28\n",
       "0                 \n",
       "0       0  2748208\n",
       "0       1  2748211\n",
       "0       2  2748212\n",
       "0       3  2748245\n",
       "0       4  2748263\n",
       "..    ...      ...\n",
       "0   56362  1413137\n",
       "0   56363  1413181\n",
       "0   56364  1414800\n",
       "0   56365  1414808\n",
       "0   56366  1416469\n",
       "\n",
       "[56367 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e0c1303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10237, 39, 11, 11)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[labels15.loc[0][\"X\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f10ad958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10237, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels15.loc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8673db95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2893058., 2870455., 2868833., ..., 1311910., 1176428., 1314791.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b0a18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preds = pd.DataFrame(np.array(preds.detach())).set_index(ID_train)\n",
    "neighbors = [w15.neighbors[x] for x in ID_train]\n",
    "transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "n_function = np.zeros((len(preds), w15.max_neighbors + 1))\n",
    "for i, (t, idx) in enumerate(zip(transitions, ID_train)):\n",
    "    n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "    n_function[i, 0] = preds.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f78e226c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .......max_depth=6, oob_score=True;, score=0.641 total time=   4.8s\n",
      "[CV 2/5] END .......max_depth=6, oob_score=True;, score=0.649 total time=   4.6s\n",
      "[CV 3/5] END .......max_depth=6, oob_score=True;, score=0.663 total time=   4.7s\n",
      "[CV 4/5] END .......max_depth=6, oob_score=True;, score=0.619 total time=   4.8s\n",
      "[CV 5/5] END .......max_depth=6, oob_score=True;, score=0.681 total time=   4.7s\n",
      "[CV 1/5] END ......max_depth=6, oob_score=False;, score=0.639 total time=   4.1s\n",
      "[CV 2/5] END ......max_depth=6, oob_score=False;, score=0.652 total time=   4.3s\n",
      "[CV 3/5] END ......max_depth=6, oob_score=False;, score=0.663 total time=   4.0s\n",
      "[CV 4/5] END ......max_depth=6, oob_score=False;, score=0.619 total time=   3.9s\n",
      "[CV 5/5] END ......max_depth=6, oob_score=False;, score=0.682 total time=   4.4s\n",
      "[CV 1/5] END .......max_depth=8, oob_score=True;, score=0.647 total time=   5.4s\n",
      "[CV 2/5] END .......max_depth=8, oob_score=True;, score=0.663 total time=   5.5s\n",
      "[CV 3/5] END .......max_depth=8, oob_score=True;, score=0.673 total time=   5.6s\n",
      "[CV 4/5] END .......max_depth=8, oob_score=True;, score=0.632 total time=   5.4s\n",
      "[CV 5/5] END .......max_depth=8, oob_score=True;, score=0.688 total time=   6.6s\n",
      "[CV 1/5] END ......max_depth=8, oob_score=False;, score=0.647 total time=   5.1s\n",
      "[CV 2/5] END ......max_depth=8, oob_score=False;, score=0.663 total time=   5.6s\n",
      "[CV 3/5] END ......max_depth=8, oob_score=False;, score=0.673 total time=   6.3s\n",
      "[CV 4/5] END ......max_depth=8, oob_score=False;, score=0.632 total time=   5.3s\n",
      "[CV 5/5] END ......max_depth=8, oob_score=False;, score=0.688 total time=   5.6s\n",
      "[CV 1/5] END ......max_depth=10, oob_score=True;, score=0.659 total time=   6.8s\n",
      "[CV 2/5] END ......max_depth=10, oob_score=True;, score=0.671 total time=   7.0s\n",
      "[CV 3/5] END ......max_depth=10, oob_score=True;, score=0.682 total time=   6.9s\n",
      "[CV 4/5] END ......max_depth=10, oob_score=True;, score=0.645 total time=   6.8s\n",
      "[CV 5/5] END ......max_depth=10, oob_score=True;, score=0.697 total time=   7.0s\n",
      "[CV 1/5] END .....max_depth=10, oob_score=False;, score=0.657 total time=   6.1s\n",
      "[CV 2/5] END .....max_depth=10, oob_score=False;, score=0.672 total time=   6.0s\n",
      "[CV 3/5] END .....max_depth=10, oob_score=False;, score=0.682 total time=   6.1s\n",
      "[CV 4/5] END .....max_depth=10, oob_score=False;, score=0.645 total time=   6.2s\n",
      "[CV 5/5] END .....max_depth=10, oob_score=False;, score=0.696 total time=   6.2s\n",
      "[CV 1/5] END ......max_depth=12, oob_score=True;, score=0.667 total time=   7.6s\n",
      "[CV 2/5] END ......max_depth=12, oob_score=True;, score=0.681 total time=   7.6s\n",
      "[CV 3/5] END ......max_depth=12, oob_score=True;, score=0.690 total time=   7.5s\n",
      "[CV 4/5] END ......max_depth=12, oob_score=True;, score=0.657 total time=   7.4s\n",
      "[CV 5/5] END ......max_depth=12, oob_score=True;, score=0.703 total time=   7.6s\n",
      "[CV 1/5] END .....max_depth=12, oob_score=False;, score=0.667 total time=   6.8s\n",
      "[CV 2/5] END .....max_depth=12, oob_score=False;, score=0.681 total time=   6.9s\n",
      "[CV 3/5] END .....max_depth=12, oob_score=False;, score=0.691 total time=   6.8s\n",
      "[CV 4/5] END .....max_depth=12, oob_score=False;, score=0.657 total time=   7.1s\n",
      "[CV 5/5] END .....max_depth=12, oob_score=False;, score=0.704 total time=   7.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [6, 8, 10, 12],\n",
       "                         'oob_score': [True, False]},\n",
       "             scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"max_depth\": [6, 8, 10, 12], \"oob_score\" : [True, False]}\n",
    "clf_bagger = GridSearchCV(RandomForestClassifier(), params, cv = 5, scoring = \"balanced_accuracy\",\n",
    "                               verbose = 3)\n",
    "oversample = SMOTE()\n",
    "x, y = oversample.fit_resample(n_function, Y_train)\n",
    "\n",
    "clf_bagger.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08a83af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'oob_score': False}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bagger.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(preds.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b249875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = torch.from_numpy(X_val).float()\n",
    "preds = model(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91e2c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w16.pickle', 'rb') as handle:\n",
    "    w16 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49d94624",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(np.array(preds.detach())).set_index(ID_val)\n",
    "neighbors = [w16.neighbors[x] for x in ID_val]\n",
    "transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "n_function = np.zeros((len(preds), w16.max_neighbors + 1))\n",
    "for i, (t, idx) in enumerate(zip(transitions, ID_val)):\n",
    "    n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "    n_function[i, 0] = preds.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee759569",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_bagger.predict(n_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f66f06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57050"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71e36a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5448808332705778"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bagger.score(n_function, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "708da41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22256568778979907"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d5b6b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1262683201803833"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "653623ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4529"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y_val == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785763ff",
   "metadata": {},
   "source": [
    "# No bagger on the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "efe1d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(np.array(preds.detach())).set_index(ID_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ba4f5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"y\"] = Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "da369a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.sort_values(by=[0], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2288054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3699708.0</th>\n",
       "      <td>9.999919e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206980.0</th>\n",
       "      <td>9.999806e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206983.0</th>\n",
       "      <td>9.999349e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206982.0</th>\n",
       "      <td>9.999343e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210563.0</th>\n",
       "      <td>9.999300e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654130.0</th>\n",
       "      <td>3.897061e-21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113362.0</th>\n",
       "      <td>1.054448e-21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705586.0</th>\n",
       "      <td>2.995088e-22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703981.0</th>\n",
       "      <td>6.478963e-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116824.0</th>\n",
       "      <td>9.653986e-25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0    y\n",
       "3699708.0  9.999919e-01  0.0\n",
       "2206980.0  9.999806e-01  0.0\n",
       "2206983.0  9.999349e-01  0.0\n",
       "2206982.0  9.999343e-01  0.0\n",
       "2210563.0  9.999300e-01  0.0\n",
       "...                 ...  ...\n",
       "2654130.0  3.897061e-21  0.0\n",
       "2113362.0  1.054448e-21  0.0\n",
       "3705586.0  2.995088e-22  0.0\n",
       "3703981.0  6.478963e-23  0.0\n",
       "2116824.0  9.653986e-25  1.0\n",
       "\n",
       "[57050 rows x 2 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "70c91604",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].iloc[0:4529] = 1\n",
    "preds[0].iloc[4529:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "4426a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17244424817840584"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(preds[\"y\"], preds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e2e24821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17244424817840584"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(preds[\"y\"], preds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
