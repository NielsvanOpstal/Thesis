{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29739892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ec31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from get_data import get_data\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed = 31)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import libpysal\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce305bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d24f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658c7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    os.getcwd()\n",
    "    df = pd.DataFrame()\n",
    "    path = \"../Data/filled/\" + str(year) + \"/\"\n",
    "    for filename in os.listdir(path):\n",
    "        df1 = pd.read_csv(path + filename)\n",
    "        if df1.geometry.isna().any():\n",
    "            print(filename)\n",
    "        df = pd.concat([df, df1])\n",
    "        \n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df.geometry = df.geometry.apply(shapely.wkt.loads)\n",
    "#     df.plot(figsize = (40,40), column = \"y\")\n",
    "#     plt.show()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop([\"Unnamed: 0\", \"index\"], axis = 1)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b392735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df15 = load_data(2015)\n",
    "# df16 = load_data(2016)\n",
    "df17 = load_data(2017)\n",
    "df18 = load_data(2018)\n",
    "df19 = load_data(2019)\n",
    "\n",
    "wt = libpysal.weights.DistanceBand.from_dataframe(df17, threshold=150, binary = True, silence_warnings = True)\n",
    "wv = libpysal.weights.DistanceBand.from_dataframe(df18, threshold=150, binary = True, silence_warnings = True)\n",
    "wtest = libpysal.weights.DistanceBand.from_dataframe(df19, threshold=150, binary = True, silence_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf36e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_train = df17[df17.columns[:-5]]\n",
    "cluster_val = df18[df18.columns[:-5]]\n",
    "cluster_test = df19[df19.columns[:-5]]\n",
    "cluster_train = ss.fit_transform(cluster_train)\n",
    "cluster_val = ss.transform(cluster_val)\n",
    "cluster_test = ss.transform(cluster_test)\n",
    "\n",
    "\n",
    "\n",
    "cluster_model = KMeans(n_clusters = 3, random_state = 1)\n",
    "train_l = pd.DataFrame(cluster_model.fit_predict(cluster_train))\n",
    "val_l = pd.DataFrame(cluster_model.predict(cluster_val))\n",
    "test_l= pd.DataFrame(cluster_model.predict(cluster_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3a174e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1242, 0: 4894, 1: 2882})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fcc38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1282, 0: 4897, 1: 2932})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(val_l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd8ef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1239, 0: 5011, 1: 2932})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0544fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_samples(grid, block, dims = 39):\n",
    "    \n",
    "    nonzero = np.transpose(grid[:,:,-2].nonzero()) # Get indices of nonzero componetns\n",
    "    size = nonzero.shape[0]\n",
    "    width = block * 2 + 1 # calculate widht and height. Needed later on\n",
    "    \n",
    "    X = np.zeros((size, width, width, dims))\n",
    "    Y = np.zeros(size)\n",
    "    ID = np.zeros(size)\n",
    "    Y_1 = np.zeros(size)\n",
    "    \n",
    "    for idx, i in enumerate(nonzero):\n",
    "        x, ID[idx], Y[idx], Y_1[idx] = get_neighbor_grid(grid, i, block)\n",
    "        X[idx] = x.reshape(width,width, dims)\n",
    "        \n",
    "    X = np.moveaxis(X, -1, 1) # order the indices correctly to make sure it works in CNN\n",
    "    X = torch.from_numpy(X).float()\n",
    "    Y = torch.from_numpy(Y).float()\n",
    "    \n",
    "    return X,ID,Y, Y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37bf83dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_neighbor_grid(full, hw, block = 1):\n",
    "    \n",
    "    # get the nonzero (built) blocks by checking if they have a ID\n",
    "\n",
    "    h = hw[0]\n",
    "    w = hw[1]\n",
    "    \n",
    "    y = full[h,w,-1]\n",
    "    ID = full[h,w,-2]\n",
    "    Y_1_train = full[h,w,-3]\n",
    "    \n",
    "    hu = h - block\n",
    "    hd = h + block\n",
    "    hshort, hextra, wshort, wextra = 0,0,0,0\n",
    "    if hu < 0:\n",
    "        hshort = 0 - hu\n",
    "        hu = 0\n",
    "    if hd >= full.shape[0]:\n",
    "        hextra = (hd - full.shape[0]) + 1\n",
    "        hd = full.shape[0]\n",
    "\n",
    "    wr = w + block\n",
    "    wl = w - block\n",
    "\n",
    "    if wr >= full.shape[1]:\n",
    "        wextra = (wr - full.shape[1]) + 1\n",
    "        wr = full.shape[1]\n",
    "    if wl < 0:\n",
    "        wshort = 0 - wl\n",
    "        wl = 0\n",
    "\n",
    "    nb = full[hu : hd + 1, wl : wr + 1, :]\n",
    "    nb = np.pad(nb, ((hshort, hextra), (wshort, wextra), (0,0)), mode = \"constant\", constant_values = 0)\n",
    "    return nb[:,:,:-3], ID, y, Y_1_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f890120d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##  trainingset\n",
    "X_train = []\n",
    "Y_train = []\n",
    "ID_train = []\n",
    "Y_1_train = []\n",
    "for filename in os.listdir(\"../Data/filled/grids/2017/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2017/\" + filename)\n",
    "    X, ID, Y, Y_1 = create_CNN_samples(n, 10)\n",
    "    X_train.append(X)\n",
    "    Y_train.append(Y)\n",
    "    ID_train.append(ID)\n",
    "    Y_1_train.append(Y_1)\n",
    "    \n",
    "block_size = X.shape[-1]\n",
    "    \n",
    "Y_train = np.concatenate(Y_train)\n",
    "ID_train = np.concatenate(ID_train)\n",
    "X_train = np.concatenate(X_train)\n",
    "\n",
    "# create Y_1_train\n",
    "Y_1_train = np.concatenate(Y_1_train)\n",
    "neighbors = [wt.neighbors[x] for x in wt.neighbors]\n",
    "Y_1_train = np.array([Y_1_train[x].sum() for x in neighbors])\n",
    "Y_1_train[np.where(Y_1_train == 0)[0]] = 0.5\n",
    "\n",
    "#reshape to rescale\n",
    "X_train = np.moveaxis(X_train, 1, -1)\n",
    "X_train = X_train.reshape(-1, 39)\n",
    "X_train = ss.fit_transform(X_train) #rescale\n",
    "# reshape to oversample, append y_1 to resample\n",
    "X_train = X_train.reshape(-1, block_size, block_size, 39)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "## validation set\n",
    "X_val = []\n",
    "Y_val = []\n",
    "ID_val = []\n",
    "Y_1_val = []\n",
    "\n",
    "for filename in os.listdir(\"../Data/filled/grids/2018/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2018/\" + filename)\n",
    "    X, ID, Y, Y_1 = create_CNN_samples(n, 10)\n",
    "    X_val.append(X)\n",
    "    Y_val.append(Y)\n",
    "    ID_val.append(ID)\n",
    "    Y_1_val.append(Y_1)\n",
    "    \n",
    "# create and transform X_val\n",
    "X_val = np.concatenate(X_val)\n",
    "X_val = np.moveaxis(X_val, 1, -1)\n",
    "X_val = X_val.reshape(-1, 39)\n",
    "X_val = ss.transform(X_val)\n",
    "X_val = X_val.reshape(-1, block_size, block_size, 39)\n",
    "X_val = np.moveaxis(X_val, -1, 1)\n",
    "\n",
    "\n",
    "# create Y_1_val\n",
    "Y_1_val = np.concatenate(Y_1_val)\n",
    "neighbors = [wv.neighbors[x] for x in wv.neighbors]\n",
    "Y_1_val = np.array([Y_1_val[x].sum() for x in neighbors])\n",
    "Y_1_val[np.where(Y_1_val == 0)[0]] = 0.5\n",
    "\n",
    "# create Y-val and ID_val\n",
    "Y_val = np.concatenate(Y_val)\n",
    "ID_val = np.concatenate(ID_val)\n",
    "X_val = torch.tensor(X_val).float().to(device)\n",
    "Y_1_val = torch.tensor(Y_1_val).float().to(device)\n",
    "\n",
    "## test set\n",
    "X_test = []\n",
    "Y_test = []\n",
    "ID_test = []\n",
    "Y_1_test = []\n",
    "\n",
    "for filename in os.listdir(\"../Data/filled/grids/2019/\"):\n",
    "    n = np.load(\"../Data/filled/grids/2019/\" + filename)\n",
    "    X, ID, Y, Y_1 = create_CNN_samples(n, 10)\n",
    "    X_test.append(X)\n",
    "    Y_test.append(Y)\n",
    "    ID_test.append(ID)\n",
    "    Y_1_test.append(Y_1)\n",
    "    \n",
    "# create and transform X_val\n",
    "X_test = np.concatenate(X_test)\n",
    "X_test = np.moveaxis(X_test, 1, -1)\n",
    "X_test = X_test.reshape(-1, 39)\n",
    "X_test = ss.transform(X_test)\n",
    "X_test = X_test.reshape(-1, block_size, block_size, 39)\n",
    "X_test = np.moveaxis(X_test, -1, 1)\n",
    "\n",
    "\n",
    "# create Y_1_val\n",
    "Y_1_test = np.concatenate(Y_1_test)\n",
    "neighbors = [wtest.neighbors[x] for x in wtest.neighbors]\n",
    "Y_1_test = np.array([Y_1_test[x].sum() for x in neighbors])\n",
    "Y_1_test[np.where(Y_1_test == 0)[0]] = 0.5\n",
    "\n",
    "# create Y-val and ID_val\n",
    "Y_test = np.concatenate(Y_test)\n",
    "ID_test = np.concatenate(ID_test)\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "Y_1_test = torch.tensor(Y_1_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ab3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y, Y1, batch_size = 32):\n",
    "    \n",
    "    idxs = rng.integers(X.shape[0], size = batch_size)\n",
    "    \n",
    "    X = X[idxs]\n",
    "    Y = Y[idxs]\n",
    "    Y1 = Y1[idxs]\n",
    "\n",
    "    return X, Y, Y1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f378973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module): # best auc = 0.58\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 15, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(in_channels = 15, out_channels = 20, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(in_channels = 20, out_channels = 5, kernel_size = (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5, 1)\n",
    "            )\n",
    "        \n",
    "        self.final = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, y1):\n",
    "#         for i in self.net:\n",
    "            \n",
    "        out = self.net(x)\n",
    "        out = out.squeeze() * y1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5b5c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module): # best auc = 0.58\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 15, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(in_channels = 15, out_channels = 20, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(180 , 150),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150,1)\n",
    "            )\n",
    "        \n",
    "        self.final = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, y1):\n",
    "#         for i in self.net:\n",
    "            \n",
    "        out = self.net(x)\n",
    "        out = out.squeeze() * y1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5937dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model3(nn.Module): # best auc = 0.58\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 5, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(in_channels = 5, out_channels = 5, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(45, 1)\n",
    "            )\n",
    "        \n",
    "        self.final = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, y1):\n",
    "#         for i in self.net:\n",
    "            \n",
    "        out = self.net(x)\n",
    "        out = out.squeeze() * y1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98f0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): # best auc = 0.58\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 5, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(in_channels = 5, out_channels = 15, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(135, 150),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150,1)\n",
    "            )\n",
    "        \n",
    "        self.final = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, y1):\n",
    "#         for i in self.net:\n",
    "            \n",
    "        out = self.net(x)\n",
    "        out = out.squeeze() * y1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "216b1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "model1 = Model1().to(device)\n",
    "model2 = Model2().to(device)\n",
    "model3 = Model3().to(device)\n",
    "\n",
    "models = [\"0\", \"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07e4a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9018, 17199) torch.Size([9111, 39, 21, 21])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape) # wat is de volgorde van X_train en X_val?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6219a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(models, X_train, Y_train, Y1_train, train_l, X_val, Y_val, Y1_val, val_l, num_epochs, lr, batch_per_e = 100):\n",
    "\n",
    "    tot_auc = 0\n",
    "    tot_model = np.NaN\n",
    "    tot_param = 0\n",
    "    \n",
    "    for c in [3]:\n",
    "\n",
    "        print(\"{}: train: {}, val: {}\".format(c,Counter(train_l[0]), Counter(val_l[0])))\n",
    "        \n",
    "        xtrain = np.append(X_train, Y1_train.reshape(-1,1), axis = 1) # append Y1 for resampling \n",
    "        \n",
    "        \n",
    "        auc_clust_hist = {}\n",
    "        f1_clust_hist = {}\n",
    "        clust_models = {}\n",
    "        param_clust_hist = {} \n",
    "\n",
    "        for clust in train_l[0].unique():\n",
    "        \n",
    "            best_auc = 0\n",
    "            best_f1 = 0\n",
    "            best_model = np.NaN\n",
    "\n",
    "            idxs = train_l[train_l[0]== clust].index\n",
    "            xt = xtrain[idxs]\n",
    "            yt = Y_train[idxs]\n",
    "            \n",
    "            if np.sum(yt==1) >10:\n",
    "                oversample = SMOTE()\n",
    "                xt, yt = oversample.fit_resample(xt, yt)\n",
    "            \n",
    "            xt[xt[:,-1]>0.5][:,-1] =  np.ceil(xt[xt[:,-1] > 0.5][:,-1]) # make y1 great again\n",
    "            y1t = xt[:,-1] # get y1_train\n",
    "            xt = np.delete(xt, 39, 1) \n",
    "\n",
    "            # reshape to grid\n",
    "            xt = xt.reshape(-1, block_size, block_size, 39)\n",
    "\n",
    "            # move axis for pytorch\n",
    "            xt = np.moveaxis(xt, -1, 1) \n",
    "            \n",
    "            xt = torch.tensor(xt).float().to(device)\n",
    "            yt = torch.tensor(yt).float().to(device)\n",
    "            y1t = torch.tensor(y1t).float().to(device)\n",
    "     \n",
    "\n",
    "            # validation set for the clusters\n",
    "            idxs = val_l[val_l[0] == clust].index\n",
    "            xv = X_val[idxs]\n",
    "            yv = Y_val[idxs]\n",
    "            y1v = Y1_val[idxs]\n",
    "\n",
    "            yv = torch.tensor(yv).float().to(device)\n",
    "            yn = yv.cpu().detach().numpy()\n",
    "            \n",
    "\n",
    "            for lr in [0.00000051, 0.0000051]:\n",
    "                for size in models:\n",
    "                    if size == \"0\":\n",
    "                        model = Model()\n",
    "                    elif size == \"1\":\n",
    "                        model = Model1()\n",
    "                    elif size == \"2\":\n",
    "                        model = Model2()\n",
    "                    else:\n",
    "                        size = Model3()\n",
    "                \n",
    "\n",
    "                    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "                    SigBCEloss = nn.BCEWithLogitsLoss()\n",
    " \n",
    "                    for epoch in range(num_epochs):\n",
    "                        epoch_loss = []\n",
    "                        model.train()\n",
    "                        for i in range(batch_per_e):\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "                            x,y, y1 = get_batch(xt, yt, y1t, 6)\n",
    "                            out = model(x, y1) # get output from final linear layer\n",
    "\n",
    "                            loss = SigBCEloss(out, y) # put through sigmoid and calculate loss\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                        \n",
    "                        model.eval()\n",
    "\n",
    "                        out = model(xv, y1v)             \n",
    "\n",
    "                        yn = yv.cpu().detach().numpy()\n",
    "\n",
    "                        ROC = roc_auc_score(yn, model.final(out).detach())\n",
    "                        out = out.cpu().squeeze().detach().numpy()\n",
    "\n",
    "\n",
    "                        preds = np.zeros(len(out))\n",
    "                        pos = out.argsort()[-((yv==1).sum()) : ]\n",
    "                        preds[pos] = 1\n",
    "\n",
    "                        acc = accuracy_score(yn, preds)\n",
    "                        f1 = f1_score(yn, preds)\n",
    "                \n",
    "                        if ROC > best_auc:\n",
    "                            print(\"best UAC in cluster {}: {}\".format(clust, ROC))\n",
    "                            best_auc = ROC\n",
    "                            best_f1 = f1\n",
    "                            param_clust_hist[clust] = [lr, size, epoch]\n",
    "                            clust_models[clust] = deepcopy(model.state_dict())\n",
    "\n",
    "            # histories for this clust\n",
    "            auc_clust_hist[clust] = best_auc\n",
    "            f1_clust_hist[clust] = best_f1\n",
    "\n",
    "        predictions = np.zeros(len(Y_val))\n",
    "        for clust in train_l[0].unique():\n",
    "        \n",
    "            idxs = val_l[val_l[0] == clust].index\n",
    "            xv = X_val[idxs]\n",
    "            y1v = Y1_val[idxs]\n",
    "            size = param_clust_hist[clust][1]\n",
    "            if size == \"0\":\n",
    "                model = Model()\n",
    "                model.load_state_dict(clust_models[clust])\n",
    "            elif size == \"1\":\n",
    "                model = Model1()\n",
    "                model.load_state_dict(clust_models[clust])\n",
    "            elif size == \"2\":\n",
    "                model = Model2()\n",
    "                model.load_state_dict(clust_models[clust])\n",
    "            else:\n",
    "                size = Model3()\n",
    "                model.load_state_dict(clust_models[clust])\n",
    "\n",
    "            preds = model(xv, y1v)\n",
    "\n",
    "            preds = preds.cpu().squeeze().detach().numpy()\n",
    "            predictions[idxs] = preds\n",
    "\n",
    "        pos_idxs = predictions.argsort()[- (Y_val == 1).sum() : ]\n",
    "        Yhat = np.zeros(len(Y_val))\n",
    "        Yhat[pos_idxs] = 1\n",
    "        auc = roc_auc_score(Y_val, predictions)\n",
    "        f1 = f1_score(Y_val, Yhat)\n",
    "\n",
    "        if auc > tot_auc:\n",
    "            print(\"auc!! {}\".format(auc))\n",
    "            tot_auc = auc\n",
    "            tot_model = clust_models\n",
    "            tot_param = param_clust_hist\n",
    "\n",
    "    return tot_model, tot_param, tot_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9eef98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: train: Counter({0: 4894, 1: 2882, 2: 1242}), val: Counter({0: 4897, 1: 2932, 2: 1282})\n",
      "best UAC in cluster 2: 0.4262341222889965\n",
      "best UAC in cluster 2: 0.4263461849189761\n",
      "best UAC in cluster 2: 0.4265937651480009\n",
      "best UAC in cluster 2: 0.4266693422705453\n",
      "best UAC in cluster 2: 0.42674752550076356\n",
      "best UAC in cluster 2: 0.42684916370004744\n",
      "best UAC in cluster 2: 0.4270889256060504\n",
      "best UAC in cluster 2: 0.4271671088362687\n",
      "best UAC in cluster 2: 0.4272296554204434\n",
      "best UAC in cluster 2: 0.42729220200461804\n",
      "best UAC in cluster 2: 0.4274589928957505\n",
      "best UAC in cluster 2: 0.4275632372027083\n",
      "best UAC in cluster 2: 0.4277039670171013\n",
      "best UAC in cluster 2: 0.4279202739540387\n",
      "best UAC in cluster 2: 0.42801669993797464\n",
      "best UAC in cluster 2: 0.4281105198142367\n",
      "best UAC in cluster 2: 0.4282877351360649\n",
      "best UAC in cluster 2: 0.42889235211642\n",
      "best UAC in cluster 2: 0.42918944839124973\n",
      "best UAC in cluster 2: 0.4292389644370547\n",
      "best UAC in cluster 2: 0.4292806621598378\n",
      "best UAC in cluster 2: 0.4293901186821435\n",
      "best UAC in cluster 2: 0.4295334546042105\n",
      "best UAC in cluster 2: 0.4295412729272323\n",
      "best UAC in cluster 2: 0.4295438790349062\n",
      "best UAC in cluster 2: 0.42978364094090915\n",
      "best UAC in cluster 2: 0.429932189078324\n",
      "best UAC in cluster 2: 0.43005467613899934\n",
      "best UAC in cluster 2: 0.430072918892717\n",
      "best UAC in cluster 2: 0.43029183193732834\n",
      "best UAC in cluster 2: 0.4302996502603501\n",
      "best UAC in cluster 2: 0.4305654732430926\n",
      "best UAC in cluster 2: 0.4306123831812235\n",
      "best UAC in cluster 2: 0.4307088091651595\n",
      "best UAC in cluster 2: 0.43092511610209694\n",
      "best UAC in cluster 2: 0.4310528153781201\n",
      "best UAC in cluster 2: 0.43126391009970966\n",
      "best UAC in cluster 2: 0.4313160322531886\n",
      "best UAC in cluster 2: 0.4317564644500852\n",
      "best UAC in cluster 2: 0.4321968966469819\n",
      "best UAC in cluster 2: 0.43224380658511286\n",
      "best UAC in cluster 2: 0.4322750798772002\n",
      "best UAC in cluster 2: 0.4325304784292468\n",
      "best UAC in cluster 2: 0.4328275747040765\n",
      "best UAC in cluster 2: 0.43303085110264417\n",
      "best UAC in cluster 2: 0.43306473050240546\n",
      "best UAC in cluster 2: 0.4331403076249498\n",
      "best UAC in cluster 2: 0.43336703899258305\n",
      "best UAC in cluster 2: 0.4333904939616485\n",
      "best UAC in cluster 2: 0.43354425431441124\n",
      "best UAC in cluster 2: 0.43357813371417253\n",
      "best UAC in cluster 2: 0.4335885581448683\n",
      "best UAC in cluster 2: 0.43370843909786977\n",
      "best UAC in cluster 2: 0.43378662232808807\n",
      "best UAC in cluster 2: 0.43412802243337484\n",
      "best UAC in cluster 2: 0.4341332346487228\n",
      "best UAC in cluster 2: 0.4341619018331362\n",
      "best UAC in cluster 2: 0.4341827506945276\n",
      "best UAC in cluster 2: 0.43424529727870237\n",
      "best UAC in cluster 2: 0.4342791766784636\n",
      "best UAC in cluster 2: 0.43452675690748843\n",
      "best UAC in cluster 2: 0.43480821653627444\n",
      "best UAC in cluster 2: 0.4349176730585801\n",
      "best UAC in cluster 2: 0.4349541585660153\n",
      "best UAC in cluster 2: 0.43499064407345056\n",
      "best UAC in cluster 2: 0.4350584028729731\n",
      "best UAC in cluster 2: 0.43520955711806186\n",
      "best UAC in cluster 2: 0.4352277998717795\n",
      "best UAC in cluster 2: 0.4353164075326936\n",
      "best UAC in cluster 2: 0.4354336823780211\n",
      "best UAC in cluster 2: 0.43561871602287117\n",
      "best UAC in cluster 2: 0.43563435266891487\n",
      "best UAC in cluster 2: 0.43588714511328747\n",
      "best UAC in cluster 2: 0.43612951312696435\n",
      "best UAC in cluster 2: 0.4362702429413574\n",
      "best UAC in cluster 2: 0.43649176209364265\n",
      "best UAC in cluster 2: 0.43653085370875183\n",
      "best UAC in cluster 2: 0.4367836461531245\n",
      "best UAC in cluster 2: 0.4369295881828653\n",
      "best UAC in cluster 2: 0.43705728745888867\n",
      "best UAC in cluster 2: 0.4370989851816718\n",
      "best UAC in cluster 2: 0.43724232110373873\n",
      "best UAC in cluster 2: 0.4373205043339571\n",
      "best UAC in cluster 2: 0.4373283226569789\n",
      "best UAC in cluster 2: 0.4375889334243733\n",
      "best UAC in cluster 2: 0.4376853594083093\n",
      "best UAC in cluster 2: 0.43781566479200656\n",
      "best UAC in cluster 2: 0.43798766789848687\n",
      "best UAC in cluster 2: 0.4382508847735553\n",
      "best UAC in cluster 2: 0.4383082191423821\n",
      "best UAC in cluster 2: 0.4383837962649264\n",
      "best UAC in cluster 2: 0.43841767566468776\n",
      "best UAC in cluster 2: 0.4385714360174505\n",
      "best UAC in cluster 2: 0.43858707266349417\n",
      "best UAC in cluster 2: 0.4387121658318435\n",
      "best UAC in cluster 2: 0.43900404989132535\n",
      "best UAC in cluster 2: 0.43906920258317395\n",
      "best UAC in cluster 2: 0.43961909130237625\n",
      "best UAC in cluster 2: 0.43970248674794243\n",
      "best UAC in cluster 2: 0.4399318242232496\n",
      "best UAC in cluster 2: 0.4403201342666674\n",
      "best UAC in cluster 2: 0.44056771449569204\n",
      "best UAC in cluster 2: 0.44072929317147663\n",
      "best UAC in cluster 2: 0.44076577867891187\n",
      "best UAC in cluster 2: 0.44076838478658587\n",
      "best UAC in cluster 2: 0.4408778413088915\n",
      "best UAC in cluster 2: 0.4409586306467838\n",
      "best UAC in cluster 2: 0.44109414824582893\n",
      "best UAC in cluster 2: 0.4412218475218522\n",
      "best UAC in cluster 2: 0.4412244536295261\n",
      "best UAC in cluster 2: 0.44126093913696135\n",
      "best UAC in cluster 2: 0.44141991170507205\n",
      "best UAC in cluster 2: 0.44146421553552906\n",
      "best UAC in cluster 2: 0.44151112547366006\n",
      "best UAC in cluster 2: 0.44197240653194825\n",
      "best UAC in cluster 2: 0.4420922874849498\n",
      "best UAC in cluster 2: 0.44218871346888566\n",
      "best UAC in cluster 2: 0.44224083562236455\n",
      "best UAC in cluster 2: 0.4424884158513893\n",
      "best UAC in cluster 2: 0.5679855308901943\n",
      "best UAC in cluster 2: 0.5680194102899555\n",
      "best UAC in cluster 2: 0.5680689263357606\n",
      "best UAC in cluster 2: 0.5681601401043486\n",
      "best UAC in cluster 2: 0.5682669905189802\n",
      "best UAC in cluster 2: 0.5683972959026775\n",
      "best UAC in cluster 2: 0.5684468119484826\n",
      "best UAC in cluster 2: 0.5696065298633879\n",
      "best UAC in cluster 2: 0.5712327410519293\n",
      "best UAC in cluster 2: 0.5720823321536352\n",
      "best UAC in cluster 2: 0.5724471872279875\n",
      "best UAC in cluster 2: 0.572848527809775\n",
      "best UAC in cluster 2: 0.5736433906503281\n",
      "best UAC in cluster 2: 0.5752148735777167\n",
      "best UAC in cluster 2: 0.578686208999411\n",
      "best UAC in cluster 2: 0.5787487555835857\n",
      "best UAC in cluster 2: 0.5807476401695013\n",
      "best UAC in cluster 2: 0.5834736287964475\n",
      "best UAC in cluster 2: 0.5836013280724707\n",
      "best UAC in cluster 2: 0.5840912763151722\n",
      "best UAC in cluster 2: 0.5845421329427647\n",
      "best UAC in cluster 2: 0.5862178601771111\n",
      "best UAC in cluster 2: 0.5870101169099904\n",
      "best UAC in cluster 2: 0.5870752696018389\n",
      "best UAC in cluster 2: 0.5875000651526919\n",
      "best UAC in cluster 2: 0.588578993729705\n",
      "best UAC in cluster 2: 0.5886571769599233\n",
      "best UAC in cluster 2: 0.589517192492325\n",
      "best UAC in cluster 2: 0.590033201811766\n",
      "best UAC in cluster 2: 0.5902521148563774\n",
      "best UAC in cluster 2: 0.5905335744851634\n",
      "best UAC in cluster 2: 0.5906951531609481\n",
      "best UAC in cluster 2: 0.59078897303721\n",
      "best UAC in cluster 2: 0.5908306707599932\n",
      "best UAC in cluster 2: 0.5908880051288199\n",
      "best UAC in cluster 2: 0.5909088539902114\n",
      "best UAC in cluster 2: 0.5909870372204298\n",
      "best UAC in cluster 2: 0.59125807241852\n",
      "best UAC in cluster 2: 0.5912737090645637\n",
      "best UAC in cluster 2: 0.5913362556487384\n",
      "best UAC in cluster 2: 0.5915082587552187\n",
      "best UAC in cluster 2: 0.5917480206612218\n",
      "best UAC in cluster 2: 0.5918209916760921\n",
      "best UAC in cluster 2: 0.5919434787367674\n",
      "best UAC in cluster 2: 0.5922744544113584\n",
      "best UAC in cluster 2: 0.5923682742876205\n",
      "best UAC in cluster 2: 0.5926966438545376\n",
      "best UAC in cluster 2: 0.5927644026540602\n",
      "best UAC in cluster 2: 0.5927826454077777\n",
      "best UAC in cluster 2: 0.5929937401293672\n",
      "best UAC in cluster 2: 0.5931240455130644\n",
      "best UAC in cluster 2: 0.5935410227408955\n",
      "best UAC in cluster 2: 0.5936035693250703\n",
      "best UAC in cluster 2: 0.5936400548325054\n",
      "best UAC in cluster 2: 0.593713025847376\n",
      "best UAC in cluster 2: 0.5938224823696816\n",
      "best UAC in cluster 2: 0.5939241205689654\n",
      "best UAC in cluster 2: 0.593989273260814\n",
      "best UAC in cluster 2: 0.5940518198449887\n",
      "best UAC in cluster 2: 0.5945313436569946\n",
      "best UAC in cluster 2: 0.5949587453155215\n",
      "best UAC in cluster 0: 0.5439482471018501\n",
      "best UAC in cluster 0: 0.5441959115199255\n",
      "best UAC in cluster 0: 0.5449083669669458\n",
      "best UAC in cluster 0: 0.5449653802125095\n",
      "best UAC in cluster 0: 0.5450483085696932\n",
      "best UAC in cluster 0: 0.545175082494104\n",
      "best UAC in cluster 0: 0.5454486620237994\n",
      "best UAC in cluster 0: 0.5456041526935187\n",
      "best UAC in cluster 0: 0.5457813560243249\n",
      "best UAC in cluster 0: 0.5458396300050485\n",
      "best UAC in cluster 0: 0.5459934396945547\n",
      "best UAC in cluster 0: 0.5461104079010553\n",
      "best UAC in cluster 0: 0.5461723240055741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best UAC in cluster 0: 0.5464701376666762\n",
      "best UAC in cluster 0: 0.5464890486940746\n",
      "best UAC in cluster 0: 0.5465862653830702\n",
      "best UAC in cluster 0: 0.5468095555880546\n",
      "best UAC in cluster 0: 0.5470577803328677\n",
      "best UAC in cluster 0: 0.5472940981345042\n",
      "best UAC in cluster 0: 0.5474826480817494\n",
      "best UAC in cluster 0: 0.547569778889466\n",
      "best UAC in cluster 0: 0.5478055363643648\n",
      "best UAC in cluster 0: 0.5479604667073463\n",
      "best UAC in cluster 0: 0.5481742313577894\n",
      "best UAC in cluster 0: 0.5484189540604918\n",
      "best UAC in cluster 0: 0.5484333824739882\n",
      "best UAC in cluster 0: 0.5486544313720216\n",
      "best UAC in cluster 0: 0.5487678975364114\n",
      "best UAC in cluster 0: 0.5488020774674128\n",
      "best UAC in cluster 0: 0.5490189239149132\n",
      "best UAC in cluster 0: 0.5490679525044644\n",
      "best UAC in cluster 0: 0.5492240035009215\n",
      "best UAC in cluster 0: 0.5494901587013419\n",
      "best UAC in cluster 0: 0.5495852741650711\n",
      "best UAC in cluster 0: 0.5496733855445788\n",
      "best UAC in cluster 0: 0.5497892330976039\n",
      "best UAC in cluster 0: 0.5501028759890467\n",
      "best UAC in cluster 0: 0.5502489811859091\n",
      "best UAC in cluster 0: 0.550407553652686\n",
      "best UAC in cluster 0: 0.5505797140428527\n",
      "best UAC in cluster 0: 0.550862679045405\n",
      "best UAC in cluster 0: 0.5510725214086838\n",
      "best UAC in cluster 0: 0.5510779845943767\n",
      "best UAC in cluster 0: 0.551470633555839\n",
      "best UAC in cluster 0: 0.5515567837917646\n",
      "best UAC in cluster 0: 0.551754439048498\n",
      "best UAC in cluster 0: 0.5518719675817363\n",
      "best UAC in cluster 0: 0.5520332016005174\n",
      "best UAC in cluster 0: 0.5521948558643517\n",
      "best UAC in cluster 0: 0.5523405408161607\n",
      "best UAC in cluster 0: 0.552704613113999\n",
      "best UAC in cluster 0: 0.5527210026710776\n",
      "best UAC in cluster 0: 0.552992340893822\n",
      "best UAC in cluster 0: 0.5530983827289369\n",
      "best UAC in cluster 0: 0.553230759920725\n",
      "best UAC in cluster 0: 0.5533487086990165\n",
      "best UAC in cluster 0: 0.5534683384575213\n",
      "best UAC in cluster 0: 0.5537790396335911\n",
      "best UAC in cluster 0: 0.5538866223672348\n",
      "best UAC in cluster 0: 0.5540484167127535\n",
      "best UAC in cluster 0: 0.5541023481612598\n",
      "best UAC in cluster 0: 0.5546058017351078\n",
      "best UAC in cluster 0: 0.5548267105514568\n",
      "best UAC in cluster 0: 0.5549558658645029\n",
      "best UAC in cluster 0: 0.5551113565342222\n",
      "best UAC in cluster 0: 0.5555911363034013\n",
      "best UAC in cluster 0: 0.5558731207341625\n",
      "best UAC in cluster 0: 0.5561504824693375\n",
      "best UAC in cluster 0: 0.5561918065662449\n",
      "best UAC in cluster 0: 0.5563080743643233\n",
      "best UAC in cluster 0: 0.5565467735545951\n",
      "best UAC in cluster 0: 0.5565789923420145\n",
      "best UAC in cluster 0: 0.5567532539574477\n",
      "best UAC in cluster 0: 0.5567669819625221\n",
      "best UAC in cluster 0: 0.5567833715196004\n",
      "best UAC in cluster 0: 0.55707320052469\n",
      "best UAC in cluster 0: 0.5572006748575229\n",
      "best UAC in cluster 0: 0.5572843036231288\n",
      "best UAC in cluster 0: 0.5574053341984779\n",
      "best UAC in cluster 0: 0.5574736940604805\n",
      "best UAC in cluster 0: 0.5576109741112237\n",
      "best UAC in cluster 0: 0.5577432112213274\n",
      "best UAC in cluster 0: 0.557898141564309\n",
      "best UAC in cluster 0: 0.5579544544014505\n",
      "best UAC in cluster 0: 0.5579991404587843\n",
      "best UAC in cluster 0: 0.5583543876105034\n",
      "best UAC in cluster 0: 0.5587408729778509\n",
      "best UAC in cluster 0: 0.5590197756115546\n",
      "best UAC in cluster 0: 0.5592947559580943\n",
      "best UAC in cluster 0: 0.5595473232351249\n",
      "best UAC in cluster 0: 0.5598028322275285\n",
      "best UAC in cluster 0: 0.5599953044619379\n",
      "best UAC in cluster 0: 0.5601446315375422\n",
      "best UAC in cluster 0: 0.5602653819495225\n",
      "best UAC in cluster 0: 0.5604049033072165\n",
      "best UAC in cluster 0: 0.5606560697674028\n",
      "best UAC in cluster 0: 0.5608184244396592\n",
      "best UAC in cluster 0: 0.560855966331087\n",
      "best UAC in cluster 0: 0.560972094047481\n",
      "best UAC in cluster 0: 0.5611436941109099\n",
      "best UAC in cluster 0: 0.561159943586304\n",
      "best UAC in cluster 0: 0.5612358678592662\n",
      "best UAC in cluster 0: 0.5614924975051452\n",
      "best UAC in cluster 0: 0.5618299542829415\n",
      "best UAC in cluster 0: 0.5620853231936607\n",
      "best UAC in cluster 0: 0.5622258251231458\n",
      "best UAC in cluster 0: 0.5624989844077879\n",
      "best UAC in cluster 0: 0.562634303314949\n",
      "best UAC in cluster 0: 0.5629118051318085\n",
      "best UAC in cluster 0: 0.5630644941678391\n",
      "best UAC in cluster 0: 0.5631107211237016\n",
      "best UAC in cluster 0: 0.5633310696133129\n",
      "best UAC in cluster 0: 0.5634700306442693\n",
      "best UAC in cluster 0: 0.5636173965762916\n",
      "best UAC in cluster 0: 0.5641617540019936\n",
      "best UAC in cluster 0: 0.5644011536006877\n",
      "best UAC in cluster 0: 0.5646603047168866\n",
      "best UAC in cluster 0: 0.5646778149274404\n",
      "best UAC in cluster 0: 0.5647513578117672\n",
      "best UAC in cluster 0: 0.5651298585231019\n",
      "best UAC in cluster 0: 0.5653371794160611\n",
      "best UAC in cluster 0: 0.5654782416722839\n",
      "best UAC in cluster 0: 0.5656279889929416\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 800\n",
    "a = train_model(models, X_train, Y_train, Y_1_train, train_l, X_val, Y_val, Y_1_val,val_l, n_epochs, 0.00000051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(len(Y_test))\n",
    "auc_clusters = {}\n",
    "f1_clusters = {}\n",
    "for clust in train_l[0].unique():\n",
    "  \n",
    "    idxs = test_l[test_l[0] == clust].index\n",
    "    xt = torch.tensor(X_test[idxs]).float().to(device)\n",
    "    yt = Y_test[idxs]\n",
    "\n",
    "    size = p[clust][1]\n",
    "    if size == \"0\":\n",
    "        model = Model()\n",
    "        model.load_state_dict(clust_models[clust])\n",
    "    elif size == \"1\":\n",
    "        model = Model1()\n",
    "        model.load_state_dict(clust_models[clust])\n",
    "    elif size == \"2\":\n",
    "        model = Model2()\n",
    "        model.load_state_dict(clust_models[clust])\n",
    "    else:\n",
    "        size = Model3()\n",
    "        model.load_state_dict(clust_models[clust])\n",
    "\n",
    "    preds = model(xt)\n",
    "    preds = preds.cpu().squeeze().detach().numpy()  \n",
    "    auc = roc_auc_score(yt, preds)\n",
    "    auc_clusters[clust] = auc\n",
    "\n",
    "    Yhat = np.zeros(len(yt))\n",
    "    pos_idxs = preds.argsort()[- (yt == 1).sum() : ]\n",
    "    Yhat[pos_idxs] = 1\n",
    "    f1_clusters[clust] = f1 = f1_score(yt, Yhat)\n",
    "\n",
    "    predictions[idxs] = preds\n",
    "\n",
    "pos_idxs = predictions.argsort()[- (Y_test == 1).sum() : ]\n",
    "Yhat = np.zeros(len(Y_test))\n",
    "Yhat[pos_idxs] = 1\n",
    "auc = roc_auc_score(Y_test, predictions)\n",
    "f1 = f1_score(Y_test, Yhat)\n",
    "\n",
    "with open (\"../Results/Denhaag.csv\", \"a+\") as f:\n",
    "    f.write(\"\\nCNN_cluster,{},{}\".format(auc,f1))\n",
    "    \n",
    "with open (\"../Results/DenhaagAUC.csv\", \"a+\") as f:\n",
    "    f.write(\"CNN_clust,{},{},{}\".format(auc_clusters[0],auc_clusters[1],auc_clusters[2]))\n",
    "    \n",
    "with open (\"../Results/Denhaagf1.csv\", \"a+\") as f:\n",
    "    f.write(\"CNN_clust,{},{},{}\".format(f1_clusters[0],f1_clusters[1],f1_clusters[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(a[-4]))\n",
    "plt.plot(a[-4], alpha = 0.5)\n",
    "plt.hlines(np.mean(a[-4]), 0, n_epochs, color = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732d37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.max(a[-2]))\n",
    "plt.plot(a[-2], alpha = 0.5)\n",
    "plt.hlines(np.mean(a[-2]), 0, n_epochs, color = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c08b1",
   "metadata": {},
   "source": [
    "BEST CNN FOUND Den haaG: AUC 0.636, model: 2, lr = 5.1e-06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588476f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_part(model, X, idxs, w):\n",
    "    preds = model(X)\n",
    "    preds = pd.DataFrame(np.array(preds.detach())).set_index(idxs)\n",
    "    \n",
    "    neighbors = [w.neighbors[x] for x in idxs]\n",
    "    transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "    n_function = np.zeros((len(preds), w.max_neighbors + 1))\n",
    "    for i, (t, idx) in enumerate(zip(transitions, idxs)):\n",
    "        n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "        n_function[i, 0] = preds.loc[idx]\n",
    "        \n",
    "    return n_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e699aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): # best auc = 0.59\n",
    "    def __init__(self, name):\n",
    "        super(Model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 60, kernel_size = (3,3)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(in_channels = 60, out_channels = 60, kernel_size = (3,3)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(60, 1))\n",
    "        \n",
    "        self.final = nn.Sigmoid()\n",
    "        self.name = name\n",
    "        \n",
    "    def forward(self, x, y1):\n",
    "#         for i in self.net:\n",
    "            \n",
    "        out = self.net(x)\n",
    "        out = out.squeeze() * y1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3768ab",
   "metadata": {},
   "source": [
    "# Neighbor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "import libpysal\n",
    "\n",
    "def load_data(year):\n",
    "    os.getcwd()\n",
    "    df = pd.DataFrame()\n",
    "    path = \"../Data/filled/\" + str(year) + \"/\"\n",
    "    for filename in os.listdir(path):\n",
    "        df1 = pd.read_csv(path + filename)\n",
    "        if df1.geometry.isna().any():\n",
    "            print(filename)\n",
    "        df = pd.concat([df, df1])\n",
    "    \n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df.geometry = df.geometry.apply(shapely.wkt.loads)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.drop([\"Unnamed: 0\", \"index\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = load_data(2015)\n",
    "df16 = load_data(2016)\n",
    "wt = libpysal.weights.DistanceBand.from_dataframe(df15, threshold=150, binary = True, silence_warnings = True)\n",
    "wv = libpysal.weights.DistanceBand.from_dataframe(df16, threshold=150, binary = True, silence_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X15 = df15[df15.columns[:-4]]\n",
    "Y15 = df15.y\n",
    "\n",
    "X16 = df16[df16.columns[:-4]]\n",
    "Y16 = df16.y\n",
    "\n",
    "X15 = pd.DataFrame(scaler.fit_transform(X15))\n",
    "X16 = pd.DataFrame(scaler.transform(X16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = KMeans(n_clusters=5, random_state=0)\n",
    "labels15 = pd.DataFrame(cluster_model.fit_predict(X15))\n",
    "labels16 = pd.DataFrame(cluster_model.predict(X16))\n",
    "\n",
    "labels15[\"X\"] = X15.index\n",
    "labels16[\"X\"] = X16.index\n",
    "\n",
    "\n",
    "labels15 = labels15.set_index(0)\n",
    "labels16 = labels16.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cbs_id_koppel.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# br.C28992R100 = br.C28992R100.map(b) # change C28992code for id\n",
    "labels15.C28 = labels15.C28.map(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[labels15.loc[0][\"X\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ad958",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels15.loc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preds = pd.DataFrame(np.array(preds.detach())).set_index(ID_train)\n",
    "neighbors = [w15.neighbors[x] for x in ID_train]\n",
    "transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "n_function = np.zeros((len(preds), w15.max_neighbors + 1))\n",
    "for i, (t, idx) in enumerate(zip(transitions, ID_train)):\n",
    "    n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "    n_function[i, 0] = preds.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e226c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [6, 8, 10, 12], \"oob_score\" : [True, False]}\n",
    "clf_bagger = GridSearchCV(RandomForestClassifier(), params, cv = 5, scoring = \"balanced_accuracy\",\n",
    "                               verbose = 3)\n",
    "oversample = SMOTE()\n",
    "x, y = oversample.fit_resample(n_function, Y_train)\n",
    "\n",
    "clf_bagger.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a83af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_bagger.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(preds.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = torch.from_numpy(X_val).float()\n",
    "preds = model(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w16.pickle', 'rb') as handle:\n",
    "    w16 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d94624",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(np.array(preds.detach())).set_index(ID_val)\n",
    "neighbors = [w16.neighbors[x] for x in ID_val]\n",
    "transitions = [preds.loc[x].values for x in neighbors]\n",
    "\n",
    "\n",
    "\n",
    "n_function = np.zeros((len(preds), w16.max_neighbors + 1))\n",
    "for i, (t, idx) in enumerate(zip(transitions, ID_val)):\n",
    "    n_function[i, 1:len(t) + 1] = t.squeeze()\n",
    "    n_function[i, 0] = preds.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee759569",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_bagger.predict(n_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e36a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bagger.score(n_function, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708da41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(Y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(Y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653623ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_val == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785763ff",
   "metadata": {},
   "source": [
    "# No bagger on the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(np.array(preds.detach())).set_index(ID_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"y\"] = Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da369a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.sort_values(by=[0], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c91604",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].iloc[0:4529] = 1\n",
    "preds[0].iloc[4529:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(preds[\"y\"], preds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e24821",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(preds[\"y\"], preds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
