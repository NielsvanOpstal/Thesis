{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fbf7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import os\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import libpysal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1addffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    os.getcwd()\n",
    "    df = pd.DataFrame()\n",
    "    path = \"../Data/filled/\" + str(year) + \"/\"\n",
    "    for filename in os.listdir(path):\n",
    "        df1 = pd.read_csv(path + filename)\n",
    "        if df1.geometry.isna().any():\n",
    "            print(filename)\n",
    "        df = pd.concat([df, df1])\n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df.geometry = df.geometry.apply(shapely.wkt.loads)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.drop([\"Unnamed: 0\", \"index\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d9e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_samples(grid, block, dims = 39):\n",
    "    \n",
    "    nonzero = np.transpose(grid[:,:,-2].nonzero()) # Get indices of nonzero componetns\n",
    "    size = nonzero.shape[0]\n",
    "    width = block * 2 + 1 # calculate widht and height. Needed later on\n",
    "    \n",
    "    X = np.zeros((size, width, width, dims))\n",
    "    Y = np.zeros(size)\n",
    "    ID = np.zeros(size)\n",
    "    Y_1 = np.zeros(size)\n",
    "    \n",
    "    for idx, i in enumerate(nonzero):\n",
    "        x, ID[idx], Y[idx], Y_1[idx] = get_neighbor_grid(grid, i, block)\n",
    "        X[idx] = x.reshape(width,width, dims)\n",
    "        \n",
    "    X = np.moveaxis(X, -1, 1) # order the indices correctly to make sure it works in CNN\n",
    "    X = torch.from_numpy(X).float()\n",
    "    Y = torch.from_numpy(Y).float()\n",
    "    \n",
    "    return X,ID,Y, Y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab9780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_grid(full, hw, block = 1):\n",
    "    \n",
    "    # get the nonzero (built) blocks by checking if they have a ID\n",
    "\n",
    "    h = hw[0]\n",
    "    w = hw[1]\n",
    "    \n",
    "    y = full[h,w,-1]\n",
    "    ID = full[h,w,-2]\n",
    "    Y_1_train = full[h,w,-3]\n",
    "    \n",
    "    hu = h - block\n",
    "    hd = h + block\n",
    "    hshort, hextra, wshort, wextra = 0,0,0,0\n",
    "    if hu < 0:\n",
    "        hshort = 0 - hu\n",
    "        hu = 0\n",
    "    if hd >= full.shape[0]:\n",
    "        hextra = (hd - full.shape[0]) + 1\n",
    "        hd = full.shape[0]\n",
    "\n",
    "    wr = w + block\n",
    "    wl = w - block\n",
    "\n",
    "    if wr >= full.shape[1]:\n",
    "        wextra = (wr - full.shape[1]) + 1\n",
    "        wr = full.shape[1]\n",
    "    if wl < 0:\n",
    "        wshort = 0 - wl\n",
    "        wl = 0\n",
    "\n",
    "    nb = full[hu : hd + 1, wl : wr + 1, :]\n",
    "    nb = np.pad(nb, ((hshort, hextra), (wshort, wextra), (0,0)), mode = \"constant\", constant_values = 0)\n",
    "    return nb[:,:,:-3], ID, y, Y_1_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab63a65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfa6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = load_data(2015).set_index(\"C28992R100\")\n",
    "df16 = load_data(2016).set_index(\"C28992R100\")\n",
    "df17 = load_data(2017).set_index(\"C28992R100\")\n",
    "df18 = load_data(2018).set_index(\"C28992R100\")\n",
    "df19 = load_data(2019).set_index(\"C28992R100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cefabf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data that is available in all years\n",
    "overlapping1517 = df17.index[df17.index.isin(df16.index[df16.index.isin(df15.index)])]\n",
    "overlapping1518 = df18.index[df18.index.isin(overlapping1517)]\n",
    "overlapping1519 = df19.index[df19.index.isin(overlapping1518)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b217974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cbs_id_koppel.pickle\", \"rb\") as f:\n",
    "    a = pickle.load(f)\n",
    "overlap_num = [a[x] for x in overlapping1519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4cd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_time(year, overlap_num):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    ID_train = []\n",
    "    Y_1_train = []\n",
    "    for filename in os.listdir(\"../Data/filled/grids/\" + str(year) + \"/\"):\n",
    "        n = np.load(\"../Data/filled/grids/\" + str(year) + \"/\" + filename)\n",
    "        X, ID, Y, Y_1 = create_CNN_samples(n, 10)\n",
    "        X_train.append(X)\n",
    "        Y_train.append(Y)\n",
    "        ID_train.append(ID)\n",
    "        Y_1_train.append(Y_1)\n",
    "\n",
    "    Y = np.concatenate(Y_train)\n",
    "    ID = np.concatenate(ID_train)\n",
    "    X = np.concatenate(X_train)\n",
    "    Y1 = np.concatenate(Y_1_train)\n",
    "    overlap = np.isin(ID, overlap_num)\n",
    "    return X[overlap], Y[overlap], ID[overlap], Y1[overlap]\n",
    "\n",
    "    \n",
    "# X15c, Y15c, ID15c, Y115c = get_cnn_time(2015, overlap_num)\n",
    "# X16c, Y16c, ID16c, Y116c = get_cnn_time(2016, overlap_num)\n",
    "# X17c, Y17c, ID17c, Y117c = get_cnn_time(2017, overlap_num)\n",
    "# X18c, Y18c, ID18c, Y118c = get_cnn_time(2018, overlap_num)\n",
    "# X19c, Y19c, ID19c, Y119c = get_cnn_time(2019, overlap_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fdc3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill X and Y\n",
    "block_size = get_cnn_time(2015, overlap_num)[0].shape[-1]\n",
    "X = np.zeros((len(overlapping1519), 5, 39, block_size, block_size))\n",
    "Y = np.zeros((len(overlapping1519), 5))\n",
    "Y_1 = np.zeros((len(overlapping1519), 5))\n",
    "ID = np.zeros((len(overlapping1519), 5))\n",
    "ss = StandardScaler()\n",
    "\n",
    "\n",
    "for i, year in enumerate([2015, 2016, 2017, 2018, 2019]):\n",
    "    X[:,i], Y[:,i], ID[:,i], Y_1[:,i] = get_cnn_time(year, overlap_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3fdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neighbor lists for all years\n",
    "\n",
    "df15 = df15.loc[overlapping1519]\n",
    "df16 = df16.loc[overlapping1519]\n",
    "df17 = df17.loc[overlapping1519]\n",
    "df18 = df18.loc[overlapping1519]\n",
    "df19 = df19.loc[overlapping1519]\n",
    "\n",
    "\n",
    "w15 = libpysal.weights.DistanceBand.from_dataframe(df15.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w16 = libpysal.weights.DistanceBand.from_dataframe(df16.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w17 = libpysal.weights.DistanceBand.from_dataframe(df17.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w18 = libpysal.weights.DistanceBand.from_dataframe(df18.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w19 = libpysal.weights.DistanceBand.from_dataframe(df19.reset_index(), threshold=150, binary = True, silence_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06e4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Y(t-1) for all years\n",
    "\n",
    "def get_y_1(y1, w):\n",
    "    neighbors = [w.neighbors[x] for x in w.neighbors]\n",
    "    y1 = np.array([y1[x].sum() for x in neighbors])\n",
    "    y1[np.where(y1 == 0)[0]] = 0.5\n",
    "\n",
    "    return y1\n",
    "\n",
    "Y1_15 = get_y_1(Y_1[:,0], w15)\n",
    "Y1_16 = get_y_1(Y_1[:,1], w16)\n",
    "Y1_17 = get_y_1(Y_1[:,2], w17)\n",
    "Y1_18 = get_y_1(Y_1[:,3], w18)\n",
    "Y1_19 = get_y_1(Y_1[:,4], w19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44832fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X train is the first three years\n",
    "X_train = X[:,:3]\n",
    "Y_train = Y[:,2]\n",
    "\n",
    "X_train = np.moveaxis(X_train, 2 ,-1)\n",
    "X_train = X_train.reshape(-1, 39)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_train = np.append(X_train.reshape(Y1_17.shape[0], -1), Y1_17.reshape(-1,1), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b216452",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_resample,Y_train_resample = smote.fit_resample(X_train,Y_train)\n",
    "\n",
    "Y1_17r = X_train_resample[:,-1]\n",
    "Y1_17r[Y1_17r>0.5] =  np.ceil(Y1_17r[Y1_17r > 0.5])\n",
    "\n",
    "X_train_resample = np.delete(X_train_resample, -1, -1)\n",
    "X_train_resample = X_train_resample.reshape(X_train_resample.shape[0], 3, block_size, block_size, 39)\n",
    "X_train_resample = np.moveaxis(X_train_resample, -1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f04e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3075e72c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val = X[:,:4]\n",
    "Y_val = Y[:,3]\n",
    "X_val = np.moveaxis(X_val, 2, -1)\n",
    "X_val = X_val.reshape(-1, 39)\n",
    "X_val = ss.transform(X_val)\n",
    "X_val = X_val.reshape(Y_val.shape[0], 4, block_size, block_size, 39)\n",
    "X_val = np.moveaxis(X_val, -1, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c339c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "def get_batch(X, Y, Y1, batch_size = 32):\n",
    "    idxs = rng.integers(len(X), size = batch_size)\n",
    "    return torch.tensor(X[idxs]).float().to(device), torch.tensor(Y[idxs]).float().to(device), torch.tensor(Y1[idxs]).float().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f7eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 39, out_channels = 15, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Conv2d(in_channels = 15, out_channels = 20, kernel_size = (4,4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.GRU = nn.GRU(input_size = 219 ,hidden_size = 80, batch_first = True)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(80,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, Y1):\n",
    "        orig = X[:,:,:,10,10] # original cells are at the center of 11*11 point\n",
    "        \n",
    "        batch_size, timesteps, C, H, W = X.size()\n",
    "        \n",
    "        c_in = X.view(batch_size * timesteps, C, H, W)\n",
    "        c_out = self.conv(c_in)\n",
    "        \n",
    "        # reshape and concatenate the original data\n",
    "        r_in = c_out.view(batch_size, timesteps, -1)\n",
    "        r_in = torch.cat((orig, r_in), axis = 2)\n",
    "        \n",
    "        h0 = torch.zeros(1, X.size(0), 80).to(device)\n",
    "        \n",
    "        X, _ = self.GRU(r_in, h0)\n",
    "        X = X[:,-1, :].unsqueeze(1)\n",
    "        X = self.net(X[:,-1])\n",
    "        X = X.squeeze() * Y1\n",
    " \n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfbaac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05cb02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, Y1_train, X_val, Y_val, Y1_val, num_epochs,lr, batch_per_e =200 ):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr = lr) \n",
    "    SigBCEloss = nn.BCEWithLogitsLoss()\n",
    "    train_loss = []\n",
    "    train_loss_history = []\n",
    "    acc_history = []\n",
    "    ROC_history = []\n",
    "    f1_score_history = []\n",
    "    val_loss_history = []\n",
    "    best_auc = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        print(\"epoch: {} of {}\".format(epoch, num_epochs))\n",
    "        for batch in range(batch_per_e):\n",
    "            x, y, y1 = get_batch(X_train, Y_train, Y1_train, 6)\n",
    "        \n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x, y1).squeeze()\n",
    "\n",
    "            \n",
    "            loss = SigBCEloss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            epoch_loss.append(loss.cpu().detach().numpy())\n",
    "                \n",
    "        model.eval()\n",
    "\n",
    "        out = np.zeros(len(X_val))\n",
    "        c_1 = 0\n",
    "        for c in range(1000, len(X_val) + 1000, 1000):\n",
    "            \n",
    "            if c >= len(X_val):\n",
    "                c = len(X_val) - 1\n",
    "            x = torch.tensor(X_val[c_1 : c]).float().to(device)\n",
    "            y1 = torch.tensor(Y1_val[c_1 : c]).float().to(device)\n",
    "            \n",
    "\n",
    "            temp_out = model(x, y1).cpu().detach().numpy()\n",
    "            out[c_1 : c] = temp_out\n",
    "            c_1 = c\n",
    "            \n",
    "            \n",
    "        val_loss = SigBCEloss(torch.tensor(out).float(), torch.tensor(Y_val).float())\n",
    "        \n",
    "        \n",
    "        preds = np.zeros(len(out))\n",
    "        pos = out.argsort()[-((Y_val == 1).sum()):]\n",
    "        preds[pos] = 1\n",
    "\n",
    "        \n",
    "        acc = accuracy_score(Y_val, preds)\n",
    "        ROC = roc_auc_score(Y_val, out)\n",
    "        if ROC > best_auc:\n",
    "            print(ROC)\n",
    "            bets_auc = ROC\n",
    "        \n",
    "        f1 = f1_score(Y_val, preds)\n",
    "\n",
    "        acc_history.append(acc)\n",
    "        ROC_history.append(ROC)\n",
    "        train_loss_history.append(np.sum(epoch_loss) / batch_per_e)\n",
    "        f1_score_history.append(f1)\n",
    "        val_loss_history.append(val_loss.detach().numpy())\n",
    "\n",
    "        \n",
    "        train_loss = []\n",
    "    print(out)\n",
    "    result = np.argmax(ROC_history)\n",
    "    print(\"best auc: {}, f1: {}, epoch: {}\".format(ROC_history[result], f1_score_history[result], result))\n",
    "    return acc_history, ROC_history, train_loss_history, f1_score_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "327949ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 of 500\n",
      "0.5041148531027496\n",
      "epoch: 1 of 500\n",
      "0.5101431071015796\n",
      "epoch: 2 of 500\n",
      "0.5170438087696018\n",
      "epoch: 3 of 500\n",
      "0.5240823826748284\n",
      "epoch: 4 of 500\n",
      "0.5306164208866629\n",
      "epoch: 5 of 500\n",
      "0.538630802048999\n",
      "epoch: 6 of 500\n",
      "0.5464219211506356\n",
      "epoch: 7 of 500\n",
      "0.5543231775180857\n",
      "epoch: 8 of 500\n",
      "0.5611610518956095\n",
      "epoch: 9 of 500\n",
      "0.5672898563132286\n",
      "epoch: 10 of 500\n",
      "0.5727089219211506\n",
      "epoch: 11 of 500\n",
      "0.5787251366237176\n",
      "epoch: 12 of 500\n",
      "0.583310280310489\n",
      "epoch: 13 of 500\n",
      "0.5877687884365681\n",
      "epoch: 14 of 500\n",
      "0.591127306194084\n",
      "epoch: 15 of 500\n",
      "0.5955214709701354\n",
      "epoch: 16 of 500\n",
      "0.5988187220866686\n",
      "epoch: 17 of 500\n",
      "0.6012153446627571\n",
      "epoch: 18 of 500\n",
      "0.6042917861678296\n",
      "epoch: 19 of 500\n",
      "0.6068119230055791\n",
      "epoch: 20 of 500\n",
      "0.6103392584506941\n",
      "epoch: 21 of 500\n",
      "0.6121801114392934\n",
      "epoch: 22 of 500\n",
      "0.6140493236590899\n",
      "epoch: 23 of 500\n",
      "0.6164644064894482\n",
      "epoch: 24 of 500\n",
      "0.6187636445357647\n",
      "epoch: 25 of 500\n",
      "0.6205253948889174\n",
      "epoch: 26 of 500\n",
      "0.6222189225632465\n",
      "epoch: 27 of 500\n",
      "0.6236794229699072\n",
      "epoch: 28 of 500\n",
      "0.6249746728878616\n",
      "epoch: 29 of 500\n",
      "0.626636942981893\n",
      "epoch: 30 of 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GEBRUI~1\\AppData\\Local\\Temp/ipykernel_14384/1627040301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_resample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1_17r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1_18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.00000051\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\GEBRUI~1\\AppData\\Local\\Temp/ipykernel_14384/185576957.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, X_train, Y_train, Y1_train, X_val, Y_val, Y1_val, num_epochs, lr, batch_per_e)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mtemp_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc_1\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mc_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 500 \n",
    "hists = train(model, X_train_resample, Y_train_resample, Y1_17r, X_val, Y_val, Y1_18, n_epochs,0.00000051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66410079",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hists[-3], alpha = 0.5)\n",
    "plt.hlines(np.mean(hists[-3]), 0, n_epochs, color = \"r\")\n",
    "plt.plot(hists[-1], alpha = 0.5, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(hists[-4]), np.argmax(hists[-4]))\n",
    "plt.plot(hists[-4], alpha = 0.5)\n",
    "plt.hlines(np.mean(hists[-4]), 0, n_epochs, color = \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ede21",
   "metadata": {},
   "source": [
    "X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547020d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0, len(X_val) + 1000, 1000):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12659c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
