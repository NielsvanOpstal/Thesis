{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbf7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import os\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import libpysal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1addffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    os.getcwd()\n",
    "    df = pd.DataFrame()\n",
    "    path = \"../Data/filled/\" + str(year) + \"/\"\n",
    "    for filename in os.listdir(path):\n",
    "        df1 = pd.read_csv(path + filename)\n",
    "        if df1.geometry.isna().any():\n",
    "            print(filename)\n",
    "        df = pd.concat([df, df1])\n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df.geometry = df.geometry.apply(shapely.wkt.loads)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.drop([\"Unnamed: 0\", \"index\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfa6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = load_data(2015).set_index(\"C28992R100\")\n",
    "df16 = load_data(2016).set_index(\"C28992R100\")\n",
    "df17 = load_data(2017).set_index(\"C28992R100\")\n",
    "df18 = load_data(2018).set_index(\"C28992R100\")\n",
    "df19 = load_data(2019).set_index(\"C28992R100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefabf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data that is available in all years\n",
    "overlapping1517 = df17.index[df17.index.isin(df16.index[df16.index.isin(df15.index)])]\n",
    "overlapping1518 = df18.index[df18.index.isin(overlapping1517)]\n",
    "overlapping1519 = df19.index[df19.index.isin(overlapping1518)]\n",
    "\n",
    "# Fill X and Y\n",
    "X = np.zeros((len(overlapping1519), 5, 40))\n",
    "Y = np.zeros((len(overlapping1519), 5))\n",
    "Y_1 = np.zeros((len(overlapping1519), 5))\n",
    "ss = StandardScaler()\n",
    "\n",
    "for i, df in enumerate([df15, df16, df17, df18, df19]):\n",
    "    X[:,i] = df[df.columns[:-3]].loc[overlapping1519]\n",
    "    Y[:,i] = df.loc[overlapping1519][\"y\"]\n",
    "    Y_1[:,i] = df.loc[overlapping1519][\"y-1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "356a2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neighbor lists for all years\n",
    "\n",
    "df15 = df15.loc[overlapping1519]\n",
    "df16 = df16.loc[overlapping1519]\n",
    "df17 = df17.loc[overlapping1519]\n",
    "df18 = df18.loc[overlapping1519]\n",
    "df19 = df19.loc[overlapping1519]\n",
    "\n",
    "\n",
    "w15 = libpysal.weights.DistanceBand.from_dataframe(df15.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w16 = libpysal.weights.DistanceBand.from_dataframe(df16.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w17 = libpysal.weights.DistanceBand.from_dataframe(df17.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w18 = libpysal.weights.DistanceBand.from_dataframe(df18.reset_index(), threshold=150, binary = True, silence_warnings = True)\n",
    "w19 = libpysal.weights.DistanceBand.from_dataframe(df19.reset_index(), threshold=150, binary = True, silence_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dedab184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Y(t-1) for all years\n",
    "\n",
    "def get_y_1(y1, w):\n",
    "    neighbors = [w.neighbors[x] for x in w.neighbors]\n",
    "    y1 = np.array([y1[x].sum() for x in neighbors])\n",
    "    y1[np.where(y1 == 0)[0]] = 0.5\n",
    "\n",
    "    return y1\n",
    "\n",
    "Y1_15 = get_y_1(Y_1[:,0], w15)\n",
    "Y1_16 = get_y_1(Y_1[:,1], w16)\n",
    "Y1_17 = get_y_1(Y_1[:,2], w17)\n",
    "Y1_18 = get_y_1(Y_1[:,3], w18)\n",
    "Y1_19 = get_y_1(Y_1[:,4], w19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c339c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "def get_batch(X, Y, Y1, batch_size = 32):\n",
    "    idxs = rng.integers(len(X), size = batch_size)\n",
    "    return torch.tensor(X[idxs]).float(), torch.tensor(Y[idxs]).float(), torch.tensor(Y1[idxs]).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "44832fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X train is the first three years\n",
    "X_train = X[:,:3]\n",
    "\n",
    "#fill X_train Y(t-1) with actual values for resampling\n",
    "X_train[:,0,39] = Y1_15\n",
    "X_train[:,1,39] = Y1_16\n",
    "X_train[:,2,39] = Y1_17\n",
    "\n",
    "X_train = X_train.reshape(-1, 40*3)\n",
    "\n",
    "\n",
    "Y_train = Y[:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3075e72c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oversample X_train using SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resample,Y_train_resample = smote.fit_resample(X_train,Y_train)\n",
    "X_train = X_train.reshape(-1,3,40)\n",
    "X_train_resample = X_train_resample.reshape(-1,3,40)\n",
    "\n",
    "# transform Y(t-1) to proper values\n",
    "X_train_resample[X_train_resample[:,0,-1]>0.5][:,0,-1] =  np.ceil(X_train_resample[X_train_resample[:,0,-1] > 0.5][:,0,-1])\n",
    "X_train_resample[X_train_resample[:,1,-1]>0.5][:,1,-1] =  np.ceil(X_train_resample[X_train_resample[:,1,-1] > 0.5][:,1,-1])\n",
    "X_train_resample[X_train_resample[:,2,-1]>0.5][:,2,-1] =  np.ceil(X_train_resample[X_train_resample[:,2,-1] > 0.5][:,2,-1])\n",
    "\n",
    "Y1_15r = X_train_resample[:,0,-1]\n",
    "Y1_16r = X_train_resample[:,1,-1]\n",
    "Y1_17r = X_train_resample[:,2,-1]\n",
    "\n",
    "X_train_resample = np.delete(X_train_resample, -1, 2)\n",
    "X_train = np.delete(X_train, -1, 2)\n",
    "\n",
    "X_train = X_train.reshape(-1, 39)\n",
    "X_train_resample = X_train_resample.reshape(-1, 39)\n",
    "\n",
    "# Fit and transform the standard scaler\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_train_resample = ss.transform(X_train_resample)\n",
    "\n",
    "X_train_resample = X_train_resample.reshape(-1,3, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d6a57c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X_val and X_test\n",
    "X_val = X[:,:4]\n",
    "Y_val = Y[:,3]\n",
    "X_val = np.delete(X_val, -1, 2)\n",
    "\n",
    "X_val = X_val.reshape(-1, 39)\n",
    "X_val = ss.transform(X_val)\n",
    "X_val = X_val.reshape(-1, 4, 39)\n",
    "\n",
    "\n",
    "\n",
    "X_test = X[:,:5]\n",
    "Y_test = Y[:,4]\n",
    "X_test = np.delete(X_test, -1, 2)\n",
    "X_test = X_test.reshape(-1, 39)\n",
    "\n",
    "X_test = ss.transform(X_test)\n",
    "X_test = X_test.reshape(-1, 4, 39)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f8f7eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.GRU = nn.GRU(input_size = 39,num_layers = 2, hidden_size = 1024, batch_first = True)\n",
    "        self.fc = nn.Linear(1024, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(512,1)\n",
    "        self.final = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h0 = torch.zeros(2, X.size(0), 1024)\n",
    "        X, _ = self.GRU(X, h0)\n",
    "        X = X[:,-1, :].unsqueeze(1)\n",
    "        X = self.drop(X)\n",
    "        X = self.fc(X[:,-1])\n",
    "        X = self.relu(X)\n",
    "        X = self.drop(X)\n",
    "        X = self.fc1(X)\n",
    "        \n",
    "        return X\n",
    "    def sig(self, X):\n",
    "        return self.final(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bfbaac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "05cb02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, Y1_train, X_val, Y_val, Y1_val, num_epochs, batch_per_e =500 ):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.0001) \n",
    "    SigBCEloss = nn.BCEWithLogitsLoss()\n",
    "    train_loss = []\n",
    "    train_loss_history = []\n",
    "    acc_history = []\n",
    "    ROC_history = []\n",
    "    f1_score_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        print(\"epoch: {} of {}\".format(epoch, num_epochs))\n",
    "        for batch in range(batch_per_e):\n",
    "            \n",
    "            x, y, y1 = get_batch(X_train, Y_train, Y1_train)\n",
    "            \n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x).squeeze()\n",
    "            out = out * y1\n",
    "            loss = SigBCEloss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 10 == 0:\n",
    "                train_loss.append(loss)\n",
    "                \n",
    "        model.eval()\n",
    "        \n",
    "        x, y, y1 = get_batch(X_val, Y_val, Y1_val, batch_size = 1000)\n",
    "        out = model(x)\n",
    "        out = model.sig(out).squeeze()\n",
    "        out *= y1\n",
    "        preds = np.zeros(len(out))\n",
    "        pos = out.argsort()[-((y==1).sum()):]\n",
    "        preds[pos] = 1\n",
    "\n",
    "        \n",
    "        acc = accuracy_score(y, preds)\n",
    "        ROC = roc_auc_score(y, preds)\n",
    "        f1 = f1_score(y, preds)\n",
    "        train_loss = (np.sum(train_loss) / (batch_per_e/10)).detach().item()\n",
    "\n",
    "        acc_history.append(acc)\n",
    "        ROC_history.append(ROC)\n",
    "        train_loss_history.append(train_loss)\n",
    "        f1_score_history.append(f1)\n",
    "        \n",
    "        \n",
    "        print(\"training_loss: {:.4f}, acc: {:.3f}, ROC: {:.3f}, f1: {:.3f}\".format(train_loss, acc, ROC , f1))\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "    return acc_history, ROC_history, train_loss_history, f1_score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327949ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 of 50\n",
      "training_loss: 0.6059, acc: 0.824, ROC: 0.558, f1: 0.214\n",
      "epoch: 1 of 50\n",
      "training_loss: 0.5946, acc: 0.826, ROC: 0.594, f1: 0.287\n",
      "epoch: 2 of 50\n"
     ]
    }
   ],
   "source": [
    "hists = train(model, X_train_resample, Y_train_resample, Y1_17r, X_val, Y_val, Y1_18, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547020d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12659c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
