{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da1a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import shapely\n",
    "import libpysal\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import os\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088846ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab4e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    os.getcwd()\n",
    "    df = pd.DataFrame()\n",
    "    path = \"../Data/filled/\" + str(year) + \"/\"\n",
    "    for filename in os.listdir(path):\n",
    "        df1 = pd.read_csv(path + filename)\n",
    "        if df1.geometry.isna().any():\n",
    "            print(filename)\n",
    "        df = pd.concat([df, df1])\n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df.geometry = df.geometry.apply(shapely.wkt.loads)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.drop([\"Unnamed: 0\", \"index\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467571ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = load_data(2015)\n",
    "df16 = load_data(2016)\n",
    "df17 = load_data(2017)\n",
    "df18 = load_data(2018)\n",
    "df19 = load_data(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277c90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df15[df15.columns[:-4]]\n",
    "Y_train = df15.y\n",
    "\n",
    "X_val = df16[df15.columns[:-4]]\n",
    "Y_val = df16.y\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = pd.DataFrame(ss.fit_transform(X_train)).set_index(df15.index)\n",
    "X_val = pd.DataFrame(ss.transform(X_val)).set_index(df16.index)\n",
    "\n",
    "# weights\n",
    "wt = libpysal.weights.DistanceBand.from_dataframe(df15, threshold=150, binary = True, silence_warnings = True)\n",
    "wv = libpysal.weights.DistanceBand.from_dataframe(df16, threshold=150, binary = True, silence_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d045a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid_searcher():\n",
    "    def __init__(self, trans_model, rule_model, X_train, Y_train, X_val, Y_val, w_train, w_val):\n",
    "        self.t0 = time.time()\n",
    "        self.tm = trans_model\n",
    "        self.rm = rule_model\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.w_train = w_train\n",
    "        self.w_val = w_val\n",
    "        \n",
    "        self.t_idx = X_train.index\n",
    "        self.v_idx = X_val.index\n",
    "\n",
    "        \n",
    "    def transition_fit(self):\n",
    "#         print(\"fitting transition model: \", self.tm)\n",
    "        oversample = SMOTE()\n",
    "        x, y = oversample.fit_resample(self.X_train, self.Y_train)\n",
    "        self.tm.fit(x, y)\n",
    "        \n",
    "        \n",
    "    def neighbor_function(self, X, idxs, w):\n",
    "\n",
    "        grid_transitions = pd.DataFrame(self.tm.predict_proba(X)).set_index(idxs)[1]\n",
    "        \n",
    "        neighbors = [w.neighbors[x] for x in idxs] # get train neighbors\n",
    "        transitions = [grid_transitions.loc[x].values for x in neighbors] # get the trans probs of neighbors\n",
    "        n_function = np.zeros((len(transitions), w.max_neighbors + 1)) # create array to hold\n",
    "\n",
    "        for i, (t, idx) in enumerate(zip(transitions, idxs)): # fill array\n",
    "            n_function[i, 1:len(t) + 1] = t\n",
    "            n_function[i, 0] = grid_transitions.loc[idx]\n",
    "\n",
    "        return pd.DataFrame(n_function).set_index(idxs)\n",
    "        \n",
    "    \n",
    "    def neighbor_fit(self):\n",
    "        n_function = self.neighbor_function(self.X_train, self.t_idx, self.w_train)\n",
    "        r\n",
    "        oversample = ADASYN()\n",
    "        x, y = oversample.fit_resample(n_function, self.Y_train)\n",
    "        self.rm.fit(x, y)\n",
    "        \n",
    "    def val(self):\n",
    "        n_func = self.neighbor_function(self.X_val, self.v_idx, self.w_val)\n",
    "        preds = self.rm.predict(n_func)\n",
    "        acc = accuracy_score(self.Y_val, preds)\n",
    "        AUC = roc_auc_score(self.Y_val, preds)\n",
    "        print(AUC)\n",
    "        f1 = f1_score(self.Y_val, preds)\n",
    "        print(\"acc: {:.3f}, AUC: {:.3f}, f1: {:.3f}\\n\".format(\n",
    "            acc, AUC, f1), time.time() - self.t0)\n",
    "        \n",
    "        return acc, AUC, f1, self.tm, self.rm \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f85dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5889280999162858\n",
      "acc: 0.406, AUC: 0.589, f1: 0.177\n",
      " 12733.029461622238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.576894508995548\n",
      "acc: 0.590, AUC: 0.577, f1: 0.179\n",
      " 10683.426564693451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5998787649141419\n",
      "acc: 0.638, AUC: 0.600, f1: 0.196\n",
      " 321.2061424255371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.6004601029978823\n",
      "acc: 0.708, AUC: 0.600, f1: 0.205\n",
      " 13172.296329975128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5652860957626223\n",
      "acc: 0.483, AUC: 0.565, f1: 0.169\n",
      " 755.4863419532776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5864461310493099\n",
      "acc: 0.538, AUC: 0.586, f1: 0.181\n",
      " 266.63809537887573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5868002545062788\n",
      "acc: 0.560, AUC: 0.587, f1: 0.182\n",
      " 264.84015917778015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5812231668751503\n",
      "acc: 0.526, AUC: 0.581, f1: 0.178\n",
      " 163.0468544960022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5694365368594595\n",
      "acc: 0.511, AUC: 0.569, f1: 0.172\n",
      " 1046.8675236701965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.5614863938872822\n",
      "acc: 0.545, AUC: 0.561, f1: 0.169\n",
      " 140.20876359939575\n"
     ]
    }
   ],
   "source": [
    "c = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "kernel = ['rbf', 'linear', 'poly']\n",
    "max_iter = [1000,10000, 100000]\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "for _ in range(50):    \n",
    "    tm = SVC(C = c[rng.integers(len(c))], gamma = gamma[rng.integers(len(gamma))], kernel = kernel[rng.integers(len(kernel))],\n",
    "             max_iter = max_iter[rng.integers(len(max_iter))], probability = True)\n",
    "    rm = RandomForestClassifier(max_depth = 10)\n",
    "    gs = grid_searcher(tm,rm, X_train, Y_train, X_val, Y_val, wt, wv)\n",
    "\n",
    "    gs.transition_fit()\n",
    "    print(\"fit\")\n",
    "    gs.neighbor_fit()\n",
    "    with open(\"../results/SVC/results.csv\", \"a\") as f:\n",
    "        f.write(str(gs.val()).strip(\"(\").strip(\")\") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c0c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
